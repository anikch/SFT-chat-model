{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIyP_0r6zuVc"
   },
   "source": [
    "# Chat Fine-tuning\n",
    "\n",
    "Quantized Low-Rank Adapter Model Fine-tuning\n",
    "\n",
    "---\n",
    "\n",
    "Built by Trelis. Find us on [HuggingFace](https://huggingface.co/Trelis).\n",
    "\n",
    "This script is commercially licensed and available for purchase per seat/user at [Trelis.com/ADVANCED-fine-tuning](https://Trelis.com).\n",
    "\n",
    "You can also purchase access to the full GitHub Repo, including:\n",
    "1. Embedding Notebook\n",
    "2. Fine-tuning Notebook Supervised Learning + Data-prep\n",
    "3. Fine-tuning Notebook Unsupervised Learning + Data-prep\n",
    "4. Dataset Preparation\n",
    "5. Quantization Notebooks (GGUF and AWQ)\n",
    "\n",
    "---\n",
    "## Getting Set Up\n",
    "### Colab Setup\n",
    "- You can run training on a free Google Colab Notebook for 7B models if you use quantization.\n",
    "- Save a copy of this notebook: Go to File -> Save a copy in Drive. (optional, but needed if you want to make changes).\n",
    "- Go to the menu -> Runtime -> Change Runtime Type - Select GPU (T4). [Make sure to comment out flash attention when loading the model if you are using a T4 as flash is only supported on newer GPUs).\n",
    "- Then go to Runtime -> Run all.\n",
    "- It takes about 2-5 mins* for the installation (which all happens in the cloud in this notebook).\n",
    "- Once all cells have run, you'll find the chat interface at the bottom.-\n",
    "- *Optionally, you can comment back in the code below to mount Google Drive. This will download the model to your Google Drive, bringing down the total start time to about 3 mins.\n",
    "\n",
    "### Setup on an Ampere GPU (A40, A6000, A100, H100) with Cuda 12.1 and Pytorch 2.2.1 - RECOMMENDED.\n",
    "Ampere architecture GPUs allow for the use of Flash Attention, which provides a speed up. Otherwise, you  need to train with fp16 instead of bf16.\n",
    "\n",
    "For the best reproducibility, run this script on an A6000 using a one-click template from Runpod ([affiliate link for sign up here](https://runpod.io/?ref=jmfkcdio), supports Trelis' YouTube channel) or VastAI ([affiliate link for sign up here](https://cloud.vast.ai/?ref_id=98762), supports Trelis' YouTube channel):\n",
    "- Runpod one-click template [here](https://runpod.io/gsc?template=ifyqsvjlzj&ref=jmfkcdio) - easier setup.\n",
    "- Vast.ai one-click template [here](https://cloud.vast.ai/?ref_id=98762&creator_id=98762&name=Fine-tuning%20Notebook%20by%20Trelis%20-%20Cuda%2012.1) - offers smaller GPUs (which are cheaper to run)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "btp19MFIf2-1",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Connect Google Drive\n",
    "\n",
    "Optional but saves time by caching the model and allows for training data to be saved on Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "xY0mnb_stFvO"
   },
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/questions/56081324/why-are-google-colab-shell-commands-not-working\n",
    "# import locale\n",
    "# def getpreferredencoding(do_setlocale = True):\n",
    "#     return \"UTF-8\"\n",
    "# locale.getpreferredencoding = getpreferredencoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qQCkuU_Gf2km",
    "outputId": "9db284b0-9d0d-4a7b-faaa-e96d44eb8963"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "UxyAJ_Qwf6TF"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# cache_dir = \"/content/drive/My Drive/huggingface_cache\"\n",
    "# os.makedirs(cache_dir, exist_ok=True) # Ensure the directory exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuYH-h55ieEK"
   },
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up a Virtual Environment (Optional but can help avoid package conflicts)\n",
    "- Run the cell below to create a setup.py file.\n",
    "- Run the following cell to execute that setup.\n",
    "- Go to the top right corner and click on the kernel.\n",
    "- Select \"trelisEnv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile setup.py\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Create virtual environment\n",
    "subprocess.run([\"python\", \"-m\", \"venv\", \"trelisEnv\"])\n",
    "\n",
    "# Activate virtual environment (This step is intended for use outside of Jupyter)\n",
    "# For Jupyter, we skip activation and directly install packages in the next steps\n",
    "\n",
    "# Install ipykernel (This may not work as intended because the environment is not activated)\n",
    "subprocess.run([\"pip\", \"install\", \"ipykernel\"])\n",
    "\n",
    "# Install Jupyter kernel (This installs the kernel but doesn't affect the current Jupyter session)\n",
    "subprocess.run([\"python\", \"-m\", \"ipykernel\", \"install\", \"--user\", \"--name=trelisEnv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (6.26.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (0.2.0)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (1.8.0)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (8.18.1)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (7.4.9)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (5.5.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from ipykernel) (1.5.8)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ipykernel) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ipykernel) (5.9.6)\n",
      "Requirement already satisfied: pyzmq>=20 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (24.0.1)\n",
      "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (6.3.3)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (5.13.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (0.19.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (3.0.41)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (2.17.2)\n",
      "Requirement already satisfied: stack-data in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (1.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (4.9.0)\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=6.1.12->ipykernel) (0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=6.1.12->ipykernel) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.0.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.12)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.16.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed kernelspec trelisEnv in /root/.local/share/jupyter/kernels/trelisenv\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "%run setup.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to wait a few moments for trelisEnv to appear in the list of Kernels to the top right of your notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stable versions for this script (DO NOT INSTALL FOR UNSLOTH, see below instead)\n",
    "!python -m pip install --upgrade pip\n",
    "!pip install transformers==4.38.1 -q -U\n",
    "!pip install bitsandbytes==0.42.0 -q -U\n",
    "!pip install peft==0.8.2 -q -U\n",
    "!pip install accelerate==0.27.2 -q -U\n",
    "!pip install flash-attn==2.5.5 -q -U\n",
    "!pip install datasets==2.17.1 -q -U\n",
    "!pip install scipy==1.12.0 -q -U\n",
    "!pip install trl==0.7.11 -q -U\n",
    "!pip install hf_transfer==0.1.5 -q -U\n",
    "!pip install huggingface_hub==0.20.3 -q -U\n",
    "!pip install wandb==0.16.3 -q -U\n",
    "\n",
    "# # latest versions (may break the script due to updates)\n",
    "# !python -m pip install --upgrade pip\n",
    "# !pip install -U -q transformers\n",
    "# !pip install -q -U bitsandbytes\n",
    "# !pip install -q -U peft\n",
    "# !pip install -q -U accelerate\n",
    "# !pip install -q datasets\n",
    "# !pip install -q -U scipy\n",
    "# !pip install -q -U trl\n",
    "# !pip install -U flash-attn -q\n",
    "# !pip install hf_transfer\n",
    "\n",
    "## Required for Yi models\n",
    "# !pip install sentencepiece -q -U\n",
    "\n",
    "!transformers-cli env\n",
    "\n",
    "# CONSIDER RESTARTING THE KERNEL AFTER INSTALL to ensure all updates are applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #If using DoRA (this may soon not be needed as DoRA will be part of transformers). DO NOT RUN THIS IF RUNNING LoRA or Unsloth LoRA\n",
    "# !pip uninstall peft -y\n",
    "# !pip install git+https://github.com/BenjaminBossan/peft.git@feat-dora -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Unsloth Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import subprocess\n",
    "# import sys\n",
    "\n",
    "# # Determine CUDA version and PyTorch version\n",
    "# cuda_version = torch.version.cuda\n",
    "# pytorch_version = torch.__version__\n",
    "# major_version, minor_version = torch.cuda.get_device_capability()\n",
    "\n",
    "# !python -m pip install --upgrade pip\n",
    "# !pip install datasets==2.17.1 -q -U\n",
    "# !pip install scipy==1.12.0 -q -U\n",
    "# !pip install trl==0.7.11 -q -U\n",
    "# !pip install hf_transfer==0.1.5 -q -U\n",
    "# !pip install huggingface_hub==0.20.3 -q -U\n",
    "# !pip install wandb==0.16.3 -q -U\n",
    "# import torch\n",
    "# import subprocess\n",
    "# import sys\n",
    "\n",
    "# # Determine CUDA version and PyTorch version\n",
    "# cuda_version = torch.version.cuda\n",
    "# pytorch_version = torch.__version__\n",
    "# major_version, minor_version = torch.cuda.get_device_capability()\n",
    "\n",
    "# print(f\"Cuda Version: {cuda_version}\\nPyTorch Version: {pytorch_version}\\nCuda Version: {major_version}.{minor_version}\")\n",
    "\n",
    "# !python -m pip install --upgrade pip\n",
    "# !pip install datasets==2.17.1 -q -U\n",
    "# !pip install scipy==1.12.0 -q -U\n",
    "# !pip install trl==0.7.11 -q -U\n",
    "# !pip install hf_transfer==0.1.5 -q -U\n",
    "# !pip install huggingface_hub==0.20.3 -q -U\n",
    "# !pip install wandb==0.16.3 -q -U\n",
    "\n",
    "# def get_install_command(cuda_version, pytorch_version, major_version):\n",
    "#     base_url = \"git+https://github.com/unslothai/unsloth.git\"\n",
    "#     ampere_path = \"_ampere\" if major_version >= 8 else \"\"\n",
    "    \n",
    "#     # Determine the appropriate CUDA path based on the CUDA version\n",
    "#     if float(cuda_version) >= 12.1:\n",
    "#         cuda_path = \"cu121\"\n",
    "#     elif float(cuda_version) >= 11.8:\n",
    "#         cuda_path = \"cu118\"\n",
    "#     else:\n",
    "#         # If CUDA version is not supported, print a warning and exit\n",
    "#         return \"Unsupported CUDA version. Please use CUDA 11.8 or greater.\"\n",
    "\n",
    "#     # Append _ampere if applicable\n",
    "#     if major_version >= 8:\n",
    "#         cuda_path += ampere_path\n",
    "\n",
    "#     # Adjust the path based on PyTorch version\n",
    "#     if \"2.1.0\" in pytorch_version:\n",
    "#         specific_path = \"\"\n",
    "#     elif \"2.1.1\" in pytorch_version:\n",
    "#         specific_path = \"_torch211\"\n",
    "#     elif \"2.2.0\" in pytorch_version:\n",
    "#         specific_path = \"_torch220\"\n",
    "#     else:\n",
    "#         # If PyTorch version is not explicitly handled, use a generic approach\n",
    "#         specific_path = \"\"\n",
    "\n",
    "#     cuda_path += specific_path\n",
    "\n",
    "#     unsloth_install_command = f'pip install -q \"unsloth[{cuda_path}] @ {base_url}\"'\n",
    "    \n",
    "#     return unsloth_install_command\n",
    "    \n",
    "# # Execute the installation command\n",
    "# install_command = get_install_command(cuda_version, pytorch_version, major_version)\n",
    "# print(f\"Running: {install_command}\")\n",
    "# subprocess.run(install_command, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Cuda Version: {cuda_version}\\nPyTorch Version: {pytorch_version}\\nCuda Version: {major_version}.{minor_version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!RECOMMENDED: SHUT DOWN THE KERNEL AFTER INSTALLING TO ENSURE ALL UPDATED PACKAGES ARE LOADED."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2792656b088c42c09dadaa8dab41d7d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Required when training models/data that are gated on HuggingFace, and required for pushing models to HuggingFace\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_HUB_ENABLE_HF_TRANSFER=True\n"
     ]
    }
   ],
   "source": [
    "%env HF_HUB_ENABLE_HF_TRANSFER=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "c8dd41732ce7463694555f3486afe470",
      "6433bf5eed7d4bd28a954df13b6f0e94",
      "18180c98496e48f2861cade3dbaf8364",
      "68892d09649a45d193192824dd8f37f5",
      "6834175de25d453f92164ebb336de22b",
      "589a72488d9c4553a18761d6966c11a2",
      "0f211d88f23a4fac9a20aaa2262240f1",
      "aaf181f19b93404f9553cb222e531ce9",
      "86587e97d3c043c99495c35d7505884b",
      "848d078ed62443e297125e6532032549",
      "6c056bb1731546598a7cdddbab3aaa07",
      "c7f822a2863d45698f4a172fa3d720b6",
      "b90890729a954284ac2e6d1a7289d488",
      "559f7b17cf8d479b89134fbac2ff0de9",
      "7ea1b3fcf3174b41b1d38155929526fb",
      "bcfb9c09464546b6aeca67d53badedcf",
      "3fbaceee3ccf4a64b80d9451d5aa5701",
      "b5afaad1a4e74b0a923cb70fa57377dc",
      "d8eabbb772c347a69ddc2cdeb2b4c01f",
      "2ef6ac7be9464d128f89b69b28e25b40",
      "06c6dd0b25764569aacdfa2bb01f696f",
      "aeb9f39902a341c59b8d346a2558d1d1",
      "387a6dba93c54678a3a5404210afd04c",
      "e5923556c18240578703e5d443e6c81c",
      "e909f9afd82d423a967dda899fb2bf1b",
      "465bf049acb64c52933fbfe50f7d4ec7",
      "ac6f2cd6604c4c9996ca09e233dd6dbe",
      "8fca51abfe404f39a540b39df8df55b0",
      "a8599580508045cfa97149579641ce83",
      "ce690f5848a347f0860e9c3d1704f021",
      "09597bc3af6144eb8ecf874aa4dce884",
      "14c7809be6de472dad580fb54ad9ca7b",
      "043f148d952e482a9029986f99161944"
     ]
    },
    "id": "E0Nl5mWL0k2T",
    "outputId": "be6ef436-747e-49eb-d211-e369e8f18408"
   },
   "outputs": [],
   "source": [
    "cache_dir='' #commnt out if you have already set Google Drive as cache_dir\n",
    "\n",
    "# using a base model here for unsupervised trial.\n",
    "# model_id = \"PY007/TinyLlama-1.1B-intermediate-step-715k-1.5T\"\n",
    "# model_id = \"meta-llama/Llama-2-7b-hf\"\n",
    "# model_id = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "# model_id = \"meta-llama/Llama-2-13b-chat-hf\"\n",
    "# model_id  = \"tiiuae/falcon-40b-instruct\"\n",
    "# model_id  = \"tiiuae/falcon-7b\"\n",
    "# model_id  = \"tiiuae/falcon-7b-instruct\"\n",
    "# model_id  = \"tiiuae/falcon-180B\"\n",
    "# model_id  = \"tiiuae/falcon-40B\"\\\n",
    "# model_id = \"Trelis/TinyLlama-1.1B-chat-SFT\"\n",
    "# model_id = \"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\"\n",
    "model_id = \"deepseek-ai/deepseek-coder-1.3b-base\"\n",
    "# model_id = \"mistralai/Mistral-7B-v0.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJ-5idQwzvg-"
   },
   "source": [
    "## Load the Model and Tokenizer for LoRA or DoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, AutoConfig\n",
    "import torch\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "# config = AutoConfig.from_pretrained(model_id)\n",
    "# config.max_position_embeddings = 4096 # (input + output) tokens can now be up to 4096\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    # config=config,\n",
    "    # quantization_config=bnb_config,\n",
    "    # rope_scaling={\"type\": \"linear\", \"factor\": 2.0},\n",
    "    device_map='auto',\n",
    "    # trust_remote_code=False,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    attn_implementation=\"flash_attention_2\", # works with Llama models and reduces memory reqs\n",
    "    cache_dir=cache_dir)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id,use_fast=True,trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Load the Model and Tokenizer For Unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from unsloth import FastLanguageModel #for unsloth\n",
    "# import torch\n",
    "\n",
    "# max_seq_length = 512*8 #you'll need to set this below for the trainer too.\n",
    "\n",
    "# # Load model\n",
    "# model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "#     model_name = model_id,\n",
    "#     max_seq_length = max_seq_length,\n",
    "#     dtype = None, # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "#     load_in_4bit = False, # Use 4bit quantization to reduce memory usage. Must be set to false to load in bf16.\n",
    "#     cache_dir=cache_dir\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check there are no parameters overflowing onto cpu (meta).\n",
    "for n, p in model.named_parameters():\n",
    "    if p.device.type == \"meta\":\n",
    "        print(f\"{n} is on meta!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16384\n",
      "32014\n"
     ]
    }
   ],
   "source": [
    "print(model.config.max_position_embeddings)\n",
    "print(model.config.eos_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z-IZkKAqNIA5"
   },
   "source": [
    "# Prepare for LoRA fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model and lists which parameters are trainable.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    non_trainable_params = 0\n",
    "    all_params = 0\n",
    "\n",
    "    print(\"Trainable Parameters:\")\n",
    "    for name, param in model.named_parameters():\n",
    "        all_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "            print(f\"  {name}\")\n",
    "        else:\n",
    "            non_trainable_params += param.numel()\n",
    "\n",
    "    print(\"\\nNon-Trainable Parameters:\")\n",
    "    for name, param in model.named_parameters():\n",
    "        if not param.requires_grad:\n",
    "            print(f\"  {name}\")\n",
    "\n",
    "    print(\n",
    "        f\"\\nSummary:\\n  Trainable params: {trainable_params}\\n  Non-Trainable params: {non_trainable_params}\\n  All params: {all_params}\\n  Trainable%: {100 * trainable_params / all_params}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard LoRA or DoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable() #Comment this in to save on VRAM\n",
    "# model = prepare_model_for_kbit_training(model) # only set this if using quantization.\n",
    "\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "peft_config = LoraConfig( #matching the Llama recipe\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        # \"self_attn.rotary_emb.inv_freq\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lora_magnitude_vector\", #required for DoRA\n",
    "        # \"input_layernorm.weight\",\n",
    "        # \"post_attention_layernorm.weight\",\n",
    "        # \"model.norm.weight\",\n",
    "        # \"lm_head.weight\",\n",
    "        # \"dense_h_to_4h\", #for falcon\n",
    "        # \"dense_4h_to_h\", #for falcon\n",
    "        # \"query_key_value\", #for falcon\n",
    "        # \"dense\" #for falcon\n",
    "    ],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    # use_dora=True # only for DoRA\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config) #move to a peft model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Unsloth LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Do model patching and add fast LoRA weights\n",
    "# model = FastLanguageModel.get_peft_model(\n",
    "#     model,\n",
    "#     r = 8,\n",
    "#     target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "#                       \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "#     lora_alpha = 32,\n",
    "#     lora_dropout = 0, # Dropout = 0 is currently optimized\n",
    "#     bias = \"none\",    # Bias = \"none\" is currently optimized\n",
    "#     use_gradient_checkpointing = True,\n",
    "#     random_state = 3407,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3PBZlO95Be0l"
   },
   "source": [
    "# Set up Tokenizer and Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaTokenizerFast(name_or_path='deepseek-ai/deepseek-coder-1.3b-base', vocab_size=32000, model_max_length=16384, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<｜begin▁of▁sentence｜>', 'eos_token': '<｜end▁of▁sentence｜>', 'pad_token': '<｜end▁of▁sentence｜>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
      "\t32000: AddedToken(\"õ\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t32001: AddedToken(\"÷\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t32002: AddedToken(\"Á\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t32003: AddedToken(\"ý\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t32004: AddedToken(\"À\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t32005: AddedToken(\"ÿ\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t32006: AddedToken(\"ø\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t32007: AddedToken(\"ú\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t32008: AddedToken(\"þ\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t32009: AddedToken(\"ü\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t32010: AddedToken(\"ù\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t32011: AddedToken(\"ö\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t32012: AddedToken(\"û\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t32013: AddedToken(\"<｜begin▁of▁sentence｜>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t32014: AddedToken(\"<｜end▁of▁sentence｜>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t32015: AddedToken(\"<｜fim▁hole｜>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t32016: AddedToken(\"<｜fim▁begin｜>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t32017: AddedToken(\"<｜fim▁end｜>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t32018: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t32019: AddedToken(\"<|User|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t32020: AddedToken(\"<|Assistant|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t32021: AddedToken(\"<|EOT|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "}\n",
      "32000\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer)\n",
    "print(tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<｜begin▁of▁sentence｜>\n",
      "<｜end▁of▁sentence｜>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.bos_token)\n",
    "print(tokenizer.eos_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<｜begin▁of▁sentence｜>\n",
      "### Instruction:\n",
      "write a quick sort algorithm in python.\n",
      "### Response:\n",
      "here you are.<｜end▁of▁sentence｜>### Instruction:\n",
      "great.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# OPTIONALLY SET THE CHAT TEMPLATE MANUALLY.\n",
    "tokenizer.chat_template = \"{% if not add_generation_prompt is defined %}\\n{% set add_generation_prompt = false %}\\n{% endif %}\\n{%- set ns = namespace(found=false) -%}\\n{%- for message in messages -%}\\n    {%- if message['role'] == 'system' -%}\\n        {%- set ns.found = true -%}\\n    {%- endif -%}\\n{%- endfor -%}\\n{{bos_token}}{%- if not ns.found -%}\\n{{'\\\\n'}}\\n{%- endif %}\\n{%- for message in messages %}\\n    {%- if message['role'] == 'system' %}\\n{{ message['content'] }}\\n    {%- else %}\\n        {%- if message['role'] == 'user' %}\\n{{'### Instruction:\\\\n' + message['content'] + '\\\\n'}}\\n        {%- else %}\\n{{'### Response:\\\\n' + message['content'] + eos_token}}\\n        {%- endif %}\\n    {%- endif %}\\n{%- endfor %}\\n{% if add_generation_prompt %}\\n{{'### Response:'}}\\n{% endif %}\"\n",
    "\n",
    "#Test the chat template\n",
    "messages=[\n",
    "    { 'role': 'user', 'content': \"write a quick sort algorithm in python.\"},\n",
    "    { 'role': 'assistant', 'content': \"here you are.\"},\n",
    "    { 'role': 'user', 'content': \"great.\"},\n",
    "]\n",
    "\n",
    "inputs = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> token is in the tokenizer. Using <pad> for pad\n"
     ]
    }
   ],
   "source": [
    "## OPTION A - set the pad token to <pad>, if not <|pad|>, if not <unk> if <unk> is in the tokenizer OR set it to the EOS token.\n",
    "if '<pad>' in tokenizer.get_vocab():\n",
    "    print('<pad> token is in the tokenizer. Using <pad> for pad')\n",
    "    # Set the pad token\n",
    "    tokenizer.pad_token = '<pad>'\n",
    "elif '<|pad|>' in tokenizer.get_vocab():\n",
    "    print('<|pad|> token is in the tokenizer. Using <|pad|> for pad')\n",
    "    # Set the pad token\n",
    "    tokenizer.pad_token = '<|pad|>'\n",
    "elif '<unk>' in tokenizer.get_vocab():\n",
    "    print('<unk> token is in the tokenizer. Using unk for pad')\n",
    "    # Set the pad token\n",
    "    tokenizer.pad_token = '<unk>'\n",
    "else:\n",
    "    print(f'Using EOS token, {tokenizer.eos_token}, for padding. WARNING, this may not be ideal for chat fine-tuning models.')\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# OPTION B - create a pad token\n",
    "# Check if the pad token is already in the tokenizer vocabulary\n",
    "# if '<pad>' not in tokenizer.get_vocab():\n",
    "#     print('pad token not in the tokenizer, adding a <pad> token')\n",
    "\n",
    "#     # Add the pad token\n",
    "#     tokenizer.add_tokens(['<pad>'])\n",
    "#     # Set the pad token\n",
    "#     tokenizer.pad_token = '<pad>'\n",
    "#     # Resize token embeddings\n",
    "#     model.resize_token_embeddings(tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer pad token ID: 32018\n",
      "Model pad token ID: 32018\n",
      "Model config pad token ID: 32018\n",
      "Number of tokens now in tokenizer: 32000\n"
     ]
    }
   ],
   "source": [
    "# Update pad token id in model and its config\n",
    "model.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# Check if they are equal\n",
    "assert model.pad_token_id == tokenizer.pad_token_id, \"The model's pad token ID does not match the tokenizer's pad token ID!\"\n",
    "\n",
    "# Print the pad token ids\n",
    "print('Tokenizer pad token ID:', tokenizer.pad_token_id)\n",
    "print('Model pad token ID:', model.pad_token_id)\n",
    "print('Model config pad token ID:', model.config.pad_token_id)\n",
    "print('Number of tokens now in tokenizer:', tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special tokens map: {'bos_token': '<｜begin▁of▁sentence｜>', 'eos_token': '<｜end▁of▁sentence｜>', 'pad_token': '<pad>'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Special tokens map:\", tokenizer.special_tokens_map)\n",
    "# print(\"All special tokens:\", tokenizer.all_special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Uncomment to switch to left padding, not recommended for unsloth.\n",
    "# tokenizer.padding_side='left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set embed and norm layers to trainable (recommended for chat fine-tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to hold the names of the trainable parameters\n",
    "# trainable_params_names = [\"word_embeddings\",\"input_layernorm\", \"ln_f\"] #for Falcon\n",
    "trainable_params_names = [\"embed_tokens\", \"input_layernorm\", \"post_attention_layernorm\"] #for Llama 2 OR Mistral.\n",
    "# trainable_params_names = [\"embed\", \"norm\"] #for DeepSeek Coder\n",
    "\n",
    "# Set modules to be trainable\n",
    "for n, p in model.named_parameters():\n",
    "    if any(k in n for k in trainable_params_names):\n",
    "        p.requires_grad_(True)\n",
    "    # else:\n",
    "    #     p.requires_grad_(False)  # Optional: Set the rest to be not trainable\n",
    "\n",
    "# Make a dictionary of trainable parameters\n",
    "trainable_params = {n: p for n, p in model.named_parameters() if p.requires_grad}\n",
    "\n",
    "# Convert trainable_params to state_dict format\n",
    "trainable_params_state_dict = {n: p.data for n, p in trainable_params.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable Parameters:\n",
      "  base_model.model.model.embed_tokens.weight\n",
      "  base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.0.input_layernorm.weight\n",
      "  base_model.model.model.layers.0.post_attention_layernorm.weight\n",
      "  base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.1.input_layernorm.weight\n",
      "  base_model.model.model.layers.1.post_attention_layernorm.weight\n",
      "  base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.2.input_layernorm.weight\n",
      "  base_model.model.model.layers.2.post_attention_layernorm.weight\n",
      "  base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.3.input_layernorm.weight\n",
      "  base_model.model.model.layers.3.post_attention_layernorm.weight\n",
      "  base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.4.input_layernorm.weight\n",
      "  base_model.model.model.layers.4.post_attention_layernorm.weight\n",
      "  base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.5.input_layernorm.weight\n",
      "  base_model.model.model.layers.5.post_attention_layernorm.weight\n",
      "  base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.6.input_layernorm.weight\n",
      "  base_model.model.model.layers.6.post_attention_layernorm.weight\n",
      "  base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.7.input_layernorm.weight\n",
      "  base_model.model.model.layers.7.post_attention_layernorm.weight\n",
      "  base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.8.input_layernorm.weight\n",
      "  base_model.model.model.layers.8.post_attention_layernorm.weight\n",
      "  base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.9.input_layernorm.weight\n",
      "  base_model.model.model.layers.9.post_attention_layernorm.weight\n",
      "  base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.10.input_layernorm.weight\n",
      "  base_model.model.model.layers.10.post_attention_layernorm.weight\n",
      "  base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.11.input_layernorm.weight\n",
      "  base_model.model.model.layers.11.post_attention_layernorm.weight\n",
      "  base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.12.input_layernorm.weight\n",
      "  base_model.model.model.layers.12.post_attention_layernorm.weight\n",
      "  base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.13.input_layernorm.weight\n",
      "  base_model.model.model.layers.13.post_attention_layernorm.weight\n",
      "  base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.14.input_layernorm.weight\n",
      "  base_model.model.model.layers.14.post_attention_layernorm.weight\n",
      "  base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.15.input_layernorm.weight\n",
      "  base_model.model.model.layers.15.post_attention_layernorm.weight\n",
      "  base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.16.mlp.gate_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.16.mlp.gate_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.16.mlp.up_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.16.mlp.up_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.16.input_layernorm.weight\n",
      "  base_model.model.model.layers.16.post_attention_layernorm.weight\n",
      "  base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.17.mlp.gate_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.17.mlp.gate_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.17.mlp.up_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.17.mlp.up_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.17.input_layernorm.weight\n",
      "  base_model.model.model.layers.17.post_attention_layernorm.weight\n",
      "  base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.18.mlp.gate_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.18.mlp.gate_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.18.mlp.up_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.18.mlp.up_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.18.input_layernorm.weight\n",
      "  base_model.model.model.layers.18.post_attention_layernorm.weight\n",
      "  base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.19.mlp.gate_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.19.mlp.gate_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.19.mlp.up_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.19.mlp.up_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.19.input_layernorm.weight\n",
      "  base_model.model.model.layers.19.post_attention_layernorm.weight\n",
      "  base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.20.mlp.gate_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.20.mlp.gate_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.20.mlp.up_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.20.mlp.up_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.20.input_layernorm.weight\n",
      "  base_model.model.model.layers.20.post_attention_layernorm.weight\n",
      "  base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.21.mlp.gate_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.21.mlp.gate_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.21.mlp.up_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.21.mlp.up_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.21.input_layernorm.weight\n",
      "  base_model.model.model.layers.21.post_attention_layernorm.weight\n",
      "  base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.22.mlp.gate_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.22.mlp.gate_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.22.mlp.up_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.22.mlp.up_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.22.input_layernorm.weight\n",
      "  base_model.model.model.layers.22.post_attention_layernorm.weight\n",
      "  base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.23.mlp.gate_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.23.mlp.gate_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.23.mlp.up_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.23.mlp.up_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight\n",
      "  base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight\n",
      "  base_model.model.model.layers.23.input_layernorm.weight\n",
      "  base_model.model.model.layers.23.post_attention_layernorm.weight\n",
      "\n",
      "Non-Trainable Parameters:\n",
      "  base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight\n",
      "  base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight\n",
      "  base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight\n",
      "  base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight\n",
      "  base_model.model.model.layers.0.mlp.gate_proj.base_layer.weight\n",
      "  base_model.model.model.layers.0.mlp.up_proj.base_layer.weight\n",
      "  base_model.model.model.layers.0.mlp.down_proj.base_layer.weight\n",
      "  base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight\n",
      "  base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight\n",
      "  base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight\n",
      "  base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight\n",
      "  base_model.model.model.layers.1.mlp.gate_proj.base_layer.weight\n",
      "  base_model.model.model.layers.1.mlp.up_proj.base_layer.weight\n",
      "  base_model.model.model.layers.1.mlp.down_proj.base_layer.weight\n",
      "  base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight\n",
      "  base_model.model.model.layers.2.self_attn.k_proj.base_layer.weight\n",
      "  base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight\n",
      "  base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight\n",
      "  base_model.model.model.layers.2.mlp.gate_proj.base_layer.weight\n",
      "  base_model.model.model.layers.2.mlp.up_proj.base_layer.weight\n",
      "  base_model.model.model.layers.2.mlp.down_proj.base_layer.weight\n",
      "  base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight\n",
      "  base_model.model.model.layers.3.self_attn.k_proj.base_layer.weight\n",
      "  base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight\n",
      "  base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight\n",
      "  base_model.model.model.layers.3.mlp.gate_proj.base_layer.weight\n",
      "  base_model.model.model.layers.3.mlp.up_proj.base_layer.weight\n",
      "  base_model.model.model.layers.3.mlp.down_proj.base_layer.weight\n",
      "  base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight\n",
      "  base_model.model.model.layers.4.self_attn.k_proj.base_layer.weight\n",
      "  base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight\n",
      "  base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight\n",
      "  base_model.model.model.layers.4.mlp.gate_proj.base_layer.weight\n",
      "  base_model.model.model.layers.4.mlp.up_proj.base_layer.weight\n",
      "  base_model.model.model.layers.4.mlp.down_proj.base_layer.weight\n",
      "  base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight\n",
      "  base_model.model.model.layers.5.self_attn.k_proj.base_layer.weight\n",
      "  base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight\n",
      "  base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight\n",
      "  base_model.model.model.layers.5.mlp.gate_proj.base_layer.weight\n",
      "  base_model.model.model.layers.5.mlp.up_proj.base_layer.weight\n",
      "  base_model.model.model.layers.5.mlp.down_proj.base_layer.weight\n",
      "  base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight\n",
      "  base_model.model.model.layers.6.self_attn.k_proj.base_layer.weight\n",
      "  base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight\n",
      "  base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight\n",
      "  base_model.model.model.layers.6.mlp.gate_proj.base_layer.weight\n",
      "  base_model.model.model.layers.6.mlp.up_proj.base_layer.weight\n",
      "  base_model.model.model.layers.6.mlp.down_proj.base_layer.weight\n",
      "  base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight\n",
      "  base_model.model.model.layers.7.self_attn.k_proj.base_layer.weight\n",
      "  base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight\n",
      "  base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight\n",
      "  base_model.model.model.layers.7.mlp.gate_proj.base_layer.weight\n",
      "  base_model.model.model.layers.7.mlp.up_proj.base_layer.weight\n",
      "  base_model.model.model.layers.7.mlp.down_proj.base_layer.weight\n",
      "  base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight\n",
      "  base_model.model.model.layers.8.self_attn.k_proj.base_layer.weight\n",
      "  base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight\n",
      "  base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight\n",
      "  base_model.model.model.layers.8.mlp.gate_proj.base_layer.weight\n",
      "  base_model.model.model.layers.8.mlp.up_proj.base_layer.weight\n",
      "  base_model.model.model.layers.8.mlp.down_proj.base_layer.weight\n",
      "  base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight\n",
      "  base_model.model.model.layers.9.self_attn.k_proj.base_layer.weight\n",
      "  base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight\n",
      "  base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight\n",
      "  base_model.model.model.layers.9.mlp.gate_proj.base_layer.weight\n",
      "  base_model.model.model.layers.9.mlp.up_proj.base_layer.weight\n",
      "  base_model.model.model.layers.9.mlp.down_proj.base_layer.weight\n",
      "  base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight\n",
      "  base_model.model.model.layers.10.self_attn.k_proj.base_layer.weight\n",
      "  base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight\n",
      "  base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight\n",
      "  base_model.model.model.layers.10.mlp.gate_proj.base_layer.weight\n",
      "  base_model.model.model.layers.10.mlp.up_proj.base_layer.weight\n",
      "  base_model.model.model.layers.10.mlp.down_proj.base_layer.weight\n",
      "  base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight\n",
      "  base_model.model.model.layers.11.self_attn.k_proj.base_layer.weight\n",
      "  base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight\n",
      "  base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight\n",
      "  base_model.model.model.layers.11.mlp.gate_proj.base_layer.weight\n",
      "  base_model.model.model.layers.11.mlp.up_proj.base_layer.weight\n",
      "  base_model.model.model.layers.11.mlp.down_proj.base_layer.weight\n",
      "  base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight\n",
      "  base_model.model.model.layers.12.self_attn.k_proj.base_layer.weight\n",
      "  base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight\n",
      "  base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight\n",
      "  base_model.model.model.layers.12.mlp.gate_proj.base_layer.weight\n",
      "  base_model.model.model.layers.12.mlp.up_proj.base_layer.weight\n",
      "  base_model.model.model.layers.12.mlp.down_proj.base_layer.weight\n",
      "  base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight\n",
      "  base_model.model.model.layers.13.self_attn.k_proj.base_layer.weight\n",
      "  base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight\n",
      "  base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight\n",
      "  base_model.model.model.layers.13.mlp.gate_proj.base_layer.weight\n",
      "  base_model.model.model.layers.13.mlp.up_proj.base_layer.weight\n",
      "  base_model.model.model.layers.13.mlp.down_proj.base_layer.weight\n",
      "  base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight\n",
      "  base_model.model.model.layers.14.self_attn.k_proj.base_layer.weight\n",
      "  base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight\n",
      "  base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight\n",
      "  base_model.model.model.layers.14.mlp.gate_proj.base_layer.weight\n",
      "  base_model.model.model.layers.14.mlp.up_proj.base_layer.weight\n",
      "  base_model.model.model.layers.14.mlp.down_proj.base_layer.weight\n",
      "  base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight\n",
      "  base_model.model.model.layers.15.self_attn.k_proj.base_layer.weight\n",
      "  base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight\n",
      "  base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight\n",
      "  base_model.model.model.layers.15.mlp.gate_proj.base_layer.weight\n",
      "  base_model.model.model.layers.15.mlp.up_proj.base_layer.weight\n",
      "  base_model.model.model.layers.15.mlp.down_proj.base_layer.weight\n",
      "  base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight\n",
      "  base_model.model.model.layers.16.self_attn.k_proj.base_layer.weight\n",
      "  base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight\n",
      "  base_model.model.model.layers.16.self_attn.o_proj.base_layer.weight\n",
      "  base_model.model.model.layers.16.mlp.gate_proj.base_layer.weight\n",
      "  base_model.model.model.layers.16.mlp.up_proj.base_layer.weight\n",
      "  base_model.model.model.layers.16.mlp.down_proj.base_layer.weight\n",
      "  base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight\n",
      "  base_model.model.model.layers.17.self_attn.k_proj.base_layer.weight\n",
      "  base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight\n",
      "  base_model.model.model.layers.17.self_attn.o_proj.base_layer.weight\n",
      "  base_model.model.model.layers.17.mlp.gate_proj.base_layer.weight\n",
      "  base_model.model.model.layers.17.mlp.up_proj.base_layer.weight\n",
      "  base_model.model.model.layers.17.mlp.down_proj.base_layer.weight\n",
      "  base_model.model.model.layers.18.self_attn.q_proj.base_layer.weight\n",
      "  base_model.model.model.layers.18.self_attn.k_proj.base_layer.weight\n",
      "  base_model.model.model.layers.18.self_attn.v_proj.base_layer.weight\n",
      "  base_model.model.model.layers.18.self_attn.o_proj.base_layer.weight\n",
      "  base_model.model.model.layers.18.mlp.gate_proj.base_layer.weight\n",
      "  base_model.model.model.layers.18.mlp.up_proj.base_layer.weight\n",
      "  base_model.model.model.layers.18.mlp.down_proj.base_layer.weight\n",
      "  base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight\n",
      "  base_model.model.model.layers.19.self_attn.k_proj.base_layer.weight\n",
      "  base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight\n",
      "  base_model.model.model.layers.19.self_attn.o_proj.base_layer.weight\n",
      "  base_model.model.model.layers.19.mlp.gate_proj.base_layer.weight\n",
      "  base_model.model.model.layers.19.mlp.up_proj.base_layer.weight\n",
      "  base_model.model.model.layers.19.mlp.down_proj.base_layer.weight\n",
      "  base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight\n",
      "  base_model.model.model.layers.20.self_attn.k_proj.base_layer.weight\n",
      "  base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight\n",
      "  base_model.model.model.layers.20.self_attn.o_proj.base_layer.weight\n",
      "  base_model.model.model.layers.20.mlp.gate_proj.base_layer.weight\n",
      "  base_model.model.model.layers.20.mlp.up_proj.base_layer.weight\n",
      "  base_model.model.model.layers.20.mlp.down_proj.base_layer.weight\n",
      "  base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight\n",
      "  base_model.model.model.layers.21.self_attn.k_proj.base_layer.weight\n",
      "  base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight\n",
      "  base_model.model.model.layers.21.self_attn.o_proj.base_layer.weight\n",
      "  base_model.model.model.layers.21.mlp.gate_proj.base_layer.weight\n",
      "  base_model.model.model.layers.21.mlp.up_proj.base_layer.weight\n",
      "  base_model.model.model.layers.21.mlp.down_proj.base_layer.weight\n",
      "  base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight\n",
      "  base_model.model.model.layers.22.self_attn.k_proj.base_layer.weight\n",
      "  base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight\n",
      "  base_model.model.model.layers.22.self_attn.o_proj.base_layer.weight\n",
      "  base_model.model.model.layers.22.mlp.gate_proj.base_layer.weight\n",
      "  base_model.model.model.layers.22.mlp.up_proj.base_layer.weight\n",
      "  base_model.model.model.layers.22.mlp.down_proj.base_layer.weight\n",
      "  base_model.model.model.layers.23.self_attn.q_proj.base_layer.weight\n",
      "  base_model.model.model.layers.23.self_attn.k_proj.base_layer.weight\n",
      "  base_model.model.model.layers.23.self_attn.v_proj.base_layer.weight\n",
      "  base_model.model.model.layers.23.self_attn.o_proj.base_layer.weight\n",
      "  base_model.model.model.layers.23.mlp.gate_proj.base_layer.weight\n",
      "  base_model.model.model.layers.23.mlp.up_proj.base_layer.weight\n",
      "  base_model.model.model.layers.23.mlp.down_proj.base_layer.weight\n",
      "  base_model.model.model.norm.weight\n",
      "  base_model.model.lm_head.weight\n",
      "\n",
      "Summary:\n",
      "  Trainable params: 73654272\n",
      "  Non-Trainable params: 1280313344\n",
      "  All params: 1353967616\n",
      "  Trainable%: 5.4398843169968405\n"
     ]
    }
   ],
   "source": [
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKOnNXiMs7k9"
   },
   "source": [
    "# Set up Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "sQ4dBAJOovzz"
   },
   "outputs": [],
   "source": [
    "from transformers import TextStreamer\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "import gc  # import Python's garbage collection module\n",
    "\n",
    "# Define a stream\n",
    "def stream(user_prompt, model_type, tokenizer, checkpoint=''):\n",
    "\n",
    "    if model_type == 'base':\n",
    "        eval_model = model\n",
    "    elif model_type == 'fine-tuned':\n",
    "        eval_model = PeftModel.from_pretrained(model, checkpoint)  # Assuming PeftModel is the intended class\n",
    "        eval_model = eval_model.to(\"cuda\")\n",
    "\n",
    "        for n, p in eval_model.named_parameters():\n",
    "            if p.device.type == \"cpu\":\n",
    "                print(f\"{n} is on cpu!\")\n",
    "        \n",
    "    else:\n",
    "        print('You must set the model_type to base or fine-tuned')\n",
    "        exit()  # or raise an exception\n",
    "\n",
    "    # print(f'Proceeding to inference with peft adapters from {checkpoint}')\n",
    "\n",
    "    eval_model.config.use_cache = True\n",
    "\n",
    "    messages=[\n",
    "        { 'role': 'user', 'content': f\"{user_prompt.strip()}\"},\n",
    "    ]\n",
    "    \n",
    "    inputs = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "    inputs = tokenizer([inputs], return_tensors=\"pt\", add_special_tokens=False).to(\"cuda\")\n",
    "\n",
    "    if \"token_type_ids\" in inputs:\n",
    "        del inputs[\"token_type_ids\"]\n",
    "    \n",
    "    streamer = TextStreamer(tokenizer)\n",
    "\n",
    "    print(f'eval_model is on: {next(eval_model.parameters()).device}')  # Debug line\n",
    "    print(f'input_ids are on: {inputs[\"input_ids\"].device}')  # Debug line\n",
    "\n",
    "    # Despite returning the usual output, the streamer will also print the generated text to stdout.\n",
    "    # _ = eval_model.generate(**inputs, streamer=streamer)\n",
    "    _ = eval_model.generate(**inputs, streamer=streamer, max_new_tokens=100, pad_token_id=tokenizer.pad_token_id, eos_token_id=tokenizer.eos_token_id)\n",
    "    \n",
    "    # Clear GPU cache and run garbage collection\n",
    "    torch.cuda.empty_cache()  # Clear GPU cache\n",
    "    gc.collect()  # Run garbage collection\n",
    "\n",
    "\n",
    "def evaluation(model_type, tokenizer, checkpoint=''):\n",
    "    questions = [\n",
    "        \"What planets are in our solar system?\",\n",
    "        \"What are the first five numbers in the Fibonacci series?\",\n",
    "        \"Generate a python code snippet to add two numbers.\"\n",
    "    ]\n",
    "\n",
    "    #Optionally provide some correct answers for comparison. This is for manual evaluation. Recommended!\n",
    "    answers = [\n",
    "        \"\",\n",
    "        \"\",\n",
    "        \"\"\n",
    "    ]\n",
    "\n",
    "    for question, answer in zip(questions, answers):\n",
    "        stream(question, model_type, tokenizer, checkpoint)\n",
    "        # print(\"Correct Answer:\", answer)\n",
    "        print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenerationConfig {\n",
      "  \"bos_token_id\": 32013,\n",
      "  \"eos_token_id\": 32014\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.generation_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H8VWH8ZDPZ4U",
    "outputId": "1973e9f1-ffd9-4b3d-e27d-5a30853d9289"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_model is on: cuda:0\n",
      "input_ids are on: cuda:0\n",
      "<｜begin▁of▁sentence｜>\n",
      "### Instruction:\n",
      "What planets are in our solar system?\n",
      "### Response:\n",
      "- Mercury\n",
      "- Venus\n",
      "- Earth\n",
      "- Mars\n",
      "- Jupiter\n",
      "- Saturn\n",
      "- Uranus\n",
      "- Neptune\n",
      "\n",
      "### Instruction:What is the distance between Earth and the Sun?\n",
      "### Response:\n",
      "- 149,597,870 km\n",
      "\n",
      "### Instruction:What is the distance between Earth and the Moon?\n",
      "### Response:\n",
      "- 384,400 km\n",
      "\n",
      "###\n",
      "\n",
      "\n",
      "\n",
      "eval_model is on: cuda:0\n",
      "input_ids are on: cuda:0\n",
      "<｜begin▁of▁sentence｜>\n",
      "### Instruction:\n",
      "What are the first five numbers in the Fibonacci series?\n",
      "### Response:\n",
      "```\n",
      "1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, 4181, 6765, 10946, 1771\n",
      "\n",
      "\n",
      "\n",
      "eval_model is on: cuda:0\n",
      "input_ids are on: cuda:0\n",
      "<｜begin▁of▁sentence｜>\n",
      "### Instruction:\n",
      "Generate a python code snippet to add two numbers.\n",
      "### Response:\n",
      "```python\n",
      "a = 10\n",
      "b = 20\n",
      "c = a + b\n",
      "print(c)\n",
      "```\n",
      "\n",
      "### Instruction:Generate a python code snippet to add two numbers.\n",
      "### Response:\n",
      "```python\n",
      "a = 10\n",
      "b = 20\n",
      "c = a + b\n",
      "print(c)\n",
      "```\n",
      "\n",
      "### Instruction:Generate a python code snippet to add two numbers.\n",
      "### Response:\n",
      "```python\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation(\"base\", tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FCc64bfnmd3j"
   },
   "source": [
    "# Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s6f4z8EYmcJ6",
    "outputId": "9ff8139a-3fd5-4330-e946-1cf34fc116a4"
   },
   "outputs": [],
   "source": [
    "## There is truncation, so don't unintentionally use datasets that are larger (unless you update the truncation parameter)!\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# dataset=\"Trelis/openassistant-guanaco-EOS\"\n",
    "# dataset=\"Trelis/openassistant-falcon\"\n",
    "# dataset=\"timdettmers/openassistant-guanaco\"\n",
    "# dataset=\"Trelis/openassistant-yi\"\n",
    "dataset=\"Trelis/openassistant-deepseek-coder\"\n",
    "# dataset=\"Trelis/openassistant-llama-style\" #for Llama 2 or Mistral models.\n",
    "\n",
    "data = load_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hXM_ObnTu4JW",
    "outputId": "8f575ca2-2132-48ba-f6b6-0eb75720eba6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row of train: {'text': '\\n### Instruction:\\n¿CUales son las etapas del desarrollo y en qué consisten según Piaget?\\n### Response:\\nJean Piaget fue un psicólogo suizo que propuso una teoría sobre el desarrollo cognitivo humano que consta de cuatro etapas:\\n\\nEtapa sensoriomotora (0-2 años): Durante esta etapa, el niño aprende a través de sus sentidos y movimientos. Descubre que sus acciones pueden tener un impacto en el entorno y comienza a formarse una idea básica de objetividad y continuidad.\\n\\nEtapa preoperatoria (2-7 años): En esta etapa, el niño comienza a desarrollar un pensamiento simbólico y a comprender que las cosas pueden representar a otras cosas. También comienzan a desarrollar un pensamiento lógico y a comprender conceptos como la causa y el efecto.\\n\\nEtapa de operaciones concretas (7-12 años): Durante esta etapa, el niño desarrolla un pensamiento lógico y comprende las relaciones causales. Empiezan a comprender que las cosas pueden tener múltiples perspectivas y que los conceptos pueden ser más complejos de lo que parecen a simple vista.\\n\\nEtapa de operaciones formales (12 años en adelante): En esta etapa, el individuo desarrolla un pensamiento abstracto y puede comprender conceptos complejos y abstractos. Son capaces de razonar hipotéticamente y tienen la capacidad de reflexionar sobre su propio pensamiento.\\n\\nEstas etapas no son lineales y algunos individuos pueden avanzar en una etapa más rápidamente que en otras. La teoría de Piaget sobre el desarrollo cognitivo ha sido ampliamente utilizada y es una base importante para la investigación y el entendimiento del desarrollo humano.<｜end▁of▁sentence｜>\\n### Instruction:\\n¿Hay otras teorías sobre las etapas del desarrollo que reafirmen o contradigan a la teoría de Piaget?'}\n"
     ]
    }
   ],
   "source": [
    "# Print first row of 'train' and 'test'\n",
    "print(\"First row of train:\", data['train'][1])\n",
    "# print(\"First row of test:\", data['test'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs: [32013, 185, 13518, 3649, 3475, 25, 185, 5895, 340, 3697, 245, 2567, 14232, 782, 254, 299, 31367, 280, 254, 1632, 440, 2311, 424, 1980, 88, 1, 279, 4924, 959, 30, 6456, 931, 6989, 4512, 276, 3956, 19825, 1980, 476, 279, 254, 20211, 2882, 285, 258, 547, 7688, 3965, 13, 185, 13518, 21289, 25, 185, 1, 8704, 424, 1980, 88, 1, 13467, 276, 245, 2882, 4315, 1064, 741, 317, 885, 629, 25041, 327, 245, 2580, 1205, 409, 2408, 13, 680, 4924, 959, 11, 437, 1632, 317, 7288, 7688, 279, 254, 8696, 2882, 11, 1064, 245, 19825, 1980, 88, 20731, 638, 4474, 1813, 851, 254, 26533, 285, 2681, 4469, 280, 699, 8907, 13, 428, 6944, 280, 245, 19825, 1980, 88, 482, 1228, 279, 3916, 26533, 285, 8489, 14658, 8979, 327, 10713, 11, 372, 254, 20731, 638, 1576, 23075, 488, 276, 4675, 26533, 409, 2764, 2007, 2681, 4469, 13, 185, 185, 29233, 3965, 638, 10738, 3956, 19825, 1980, 476, 279, 19656, 1109, 372, 11437, 285, 4299, 3411, 11, 1064, 245, 1853, 2307, 5201, 2675, 245, 4474, 10265, 280, 254, 2882, 334, 33, 430, 657, 573, 363, 262, 4109, 11, 207, 17, 15, 16, 18, 628, 680, 1067, 19656, 11, 10713, 2741, 3048, 2485, 26533, 11, 6417, 7464, 11, 285, 8489, 23186, 13433, 1813, 11, 5877, 276, 245, 5425, 1064, 653, 417, 13650, 331, 254, 20731, 327, 699, 21347, 16127, 13, 997, 14471, 482, 1228, 279, 3559, 895, 4824, 280, 26533, 285, 245, 20707, 279, 2681, 4469, 13, 185, 185, 4317, 435, 11, 254, 6407, 280, 19825, 1980, 88, 317, 6024, 276, 6715, 254, 12051, 280, 8696, 12515, 285, 254, 5442, 280, 2882, 1813, 331, 10713, 13, 10340, 3965, 317, 4059, 276, 2569, 254, 10814, 285, 5442, 280, 19825, 1980, 476, 331, 254, 10966, 285, 276, 2034, 11814, 276, 2983, 437, 3605, 13, 185, 185, 2224, 5847, 25, 185, 33, 430, 657, 11, 565, 1787, 573, 363, 262, 4109, 11, 412, 13, 334, 17, 15, 16, 18, 628, 428, 11823, 280, 9792, 387, 15544, 1801, 285, 19179, 21989, 2609, 909, 372, 9162, 3617, 280, 432, 708, 279, 9165, 207, 16, 3043, 1617, 680, 11961, 13, 11898, 280, 27184, 15513, 976, 1801, 11, 207, 17, 22, 7, 18, 650, 207, 20, 22, 12, 22, 23, 13, 32014, 185, 13518, 3649, 3475, 25, 185, 4375, 6717, 359, 276, 245, 5014]\n",
      "Decoded Text: <｜begin▁of▁sentence｜>\n",
      "### Instruction:\n",
      "Can you write a short introduction about the relevance of the term \"monopsony\" in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.\n",
      "### Response:\n",
      "\"Monopsony\" refers to a market structure where there is only one buyer for a particular good or service. In economics, this term is particularly relevant in the labor market, where a monopsony employer has significant power over the wages and working conditions of their employees. The presence of a monopsony can result in lower wages and reduced employment opportunities for workers, as the employer has little incentive to increase wages or provide better working conditions.\n",
      "\n",
      "Recent research has identified potential monopsonies in industries such as retail and fast food, where a few large companies control a significant portion of the market (Bivens & Mishel, 2013). In these industries, workers often face low wages, limited benefits, and reduced bargaining power, leading to a situation where they are dependent on the employer for their livelihood. This dependence can result in further suppression of wages and a decline in working conditions.\n",
      "\n",
      "Overall, the concept of monopsony is essential to understanding the dynamics of labor markets and the impact of market power on workers. Further research is needed to understand the extent and impact of monopsonies on the economy and to develop policies to address this issue.\n",
      "\n",
      "References:\n",
      "Bivens, J., & Mishel, L. (2013). The Pay of Corporate Executives and Financial Professionals as Evidence of Rents in Top 1 Percent Incomes. Journal of Economic Perspectives, 27(3), 57-78.<｜end▁of▁sentence｜>\n",
      "### Instruction:\n",
      "Now explain it to a dog\n"
     ]
    }
   ],
   "source": [
    "# Extract text from the first row of 'test' in data\n",
    "text = data['train'][0]['text']\n",
    "\n",
    "# Tokenize the text\n",
    "tokens = tokenizer.encode(text, add_special_tokens=True)\n",
    "\n",
    "# Decode back to text\n",
    "decoded_text = tokenizer.decode(tokens)\n",
    "\n",
    "# Print tokens and decoded text\n",
    "print(\"Token IDs:\", tokens)\n",
    "print(\"Decoded Text:\", decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_0MOtwf3zdZp"
   },
   "source": [
    "# Train!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmq2Dz834gtm"
   },
   "source": [
    "## Set up and run Training (with saving of data logs to Drive)\n",
    "Using the TRL trainer is recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I98neAx6Looa"
   },
   "source": [
    "### TRL Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dr0Aw9RRPxl3",
    "outputId": "41d215c4-68ce-4e40-82bd-100acc5adf93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./results/deepseek-coder-1.3b-base_openassistant-deepseek-coder_1_epochs_4096_length-chat-fine-tuned-model\n"
     ]
    }
   ],
   "source": [
    "model_name = model_id.split(\"/\")[-1]\n",
    "dataset_name = dataset.split(\"/\")[-1]\n",
    "\n",
    "epochs=1\n",
    "context_length = 512*8\n",
    "grad_accum=8\n",
    "batch_size=4\n",
    "fine_tune_tag='chat-fine-tuned-model'\n",
    "save_dir = f'./results/{model_name}_{dataset_name}_{epochs}_epochs_{context_length}_length-{fine_tune_tag}'\n",
    "print(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "wsEO0n1ShaIJ"
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "import os\n",
    "\n",
    "# Custom callback to log metrics\n",
    "class LoggingCallback(transformers.TrainerCallback):\n",
    "    def __init__(self, log_file_path):\n",
    "        self.log_file_path = log_file_path\n",
    "        self.save_dir = save_dir\n",
    "\n",
    "    def on_log(self, args, state, control, model=None, logs=None, **kwargs):\n",
    "        with open(self.log_file_path, 'a') as f:\n",
    "            if 'loss' in logs:\n",
    "                f.write(f\"Step: {state.global_step}, Training Loss: {logs['loss']}\\n\")\n",
    "            if 'eval_loss' in logs:\n",
    "                f.write(f\"Step: {state.global_step}, Eval Loss: {logs['eval_loss']}\\n\")\n",
    "            f.flush()  # Force flush the buffered data to file\n",
    "\n",
    "        # Check if the current step is a checkpoint step\n",
    "        if state.global_step % int(args.save_steps) == 0:\n",
    "            # Check if the last checkpoint path exists\n",
    "            if state.best_model_checkpoint:\n",
    "                checkpoint_dir = state.best_model_checkpoint\n",
    "            else:\n",
    "                # If not, construct the checkpoint directory path manually\n",
    "                checkpoint_dir = os.path.join(args.output_dir, f\"checkpoint-{state.global_step}\")\n",
    "    \n",
    "            # Ensure the checkpoint directory exists\n",
    "            os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "            # Save trainable params in the checkpoint directory\n",
    "            current_trainable_params = {n: p for n, p in model.named_parameters() if p.requires_grad}\n",
    "            current_trainable_params_state_dict = {n: p.data for n, p in current_trainable_params.items()}\n",
    "            file_path = os.path.join(checkpoint_dir, \"trainable_params.bin\")\n",
    "            torch.save(current_trainable_params_state_dict, file_path)\n",
    "\n",
    "# Log file path\n",
    "log_file_path = os.path.join(cache_dir, \"training_logs.txt\")\n",
    "\n",
    "# Create an instance of the custom callback\n",
    "logging_callback = LoggingCallback(log_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from functools import reduce\n",
    "from typing import Callable, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from peft.tuners import lora\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.data.data_collator import DataCollator\n",
    "from transformers.pytorch_utils import ALL_LAYERNORM_LAYERS\n",
    "from transformers.trainer import (EvalPrediction, PreTrainedModel,\n",
    "                                  PreTrainedTokenizerBase, TrainerCallback)\n",
    "from transformers.trainer_pt_utils import get_parameter_names\n",
    "from transformers.utils import is_sagemaker_mp_enabled, logging\n",
    "\n",
    "logger = logging.get_logger(__name__)\n",
    "\n",
    "def get_module(name, opt_model):\n",
    "    \"\"\"\n",
    "    Retrieve a module from a model using its parameter name.\n",
    "    Args:\n",
    "        name (str): Full name of the parameter, typically including module path.\n",
    "        opt_model (torch.nn.Module): The model from which to retrieve the module.\n",
    "\n",
    "    Returns:\n",
    "        Module corresponding to the given name.\n",
    "    \"\"\"\n",
    "    parent_idx = 2 if \"lora\" in name else 1\n",
    "    module_names = name.split(sep=\".\")[:-parent_idx]\n",
    "    module = reduce(getattr, module_names, opt_model)\n",
    "    return module\n",
    "\n",
    "def create_loraplus_optimizer(\n",
    "    opt_model,\n",
    "    optimizer_cls,\n",
    "    optimizer_kwargs,\n",
    "    loraplus_lr_ratio,\n",
    "    loraplus_lr_embedding=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates an optimizer for the given model, applying LoRA-specific learning rate adjustments to different parameter groups.\n",
    "    \n",
    "    Args:\n",
    "        opt_model (torch.nn.Module): The model for which the optimizer is being created.\n",
    "        optimizer_cls (class): The class of the optimizer to be used (e.g., torch.optim.Adam).\n",
    "        optimizer_kwargs (dict): A dictionary of keyword arguments for the optimizer's initialization.\n",
    "        loraplus_lr_ratio (float): The learning rate ratio to be applied to LoRA parameters.\n",
    "        loraplus_lr_embedding (float, optional): A specific learning rate for embedding parameters, with a default value if not provided.\n",
    "    \n",
    "    Returns:\n",
    "        An instance of the specified optimizer class configured with the model's parameters organized into groups with custom learning rates.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert loraplus_lr_ratio is not None, \"loraplus_lr_ratio must be provided.\"\n",
    "\n",
    "    lr = optimizer_kwargs[\"lr\"]\n",
    "\n",
    "    if loraplus_lr_embedding is None:\n",
    "        loraplus_lr_embedding = lr\n",
    "\n",
    "    decay_parameters = get_parameter_names(opt_model, ALL_LAYERNORM_LAYERS)\n",
    "    decay_parameters = [name for name in decay_parameters if \"bias\" not in name]\n",
    "    param_groups = {\n",
    "        \"groupA\": {},\n",
    "        \"groupB\": {},\n",
    "        \"groupB_no_decay\": {},\n",
    "        \"embedding\": {},\n",
    "    }\n",
    "\n",
    "    for name, param in opt_model.named_parameters():\n",
    "        if not param.requires_grad:\n",
    "            continue\n",
    "\n",
    "        module = get_module(name, opt_model)\n",
    "        if isinstance(module, lora.Embedding):\n",
    "            param_groups[\"embedding\"][name] = param\n",
    "        elif \"lora_B\" in name or param.ndim == 1:\n",
    "            if name in decay_parameters:\n",
    "                param_groups[\"groupB\"][name] = param\n",
    "            else:\n",
    "                param_groups[\"groupB_no_decay\"][name] = param\n",
    "        else:\n",
    "            param_groups[\"groupA\"][name] = param\n",
    "\n",
    "    assigned_param_groups = \"\"\n",
    "    for group in param_groups:\n",
    "        assigned_param_groups += f\"{group}\\n {list(param_groups[group].keys())}\\n\\n\"\n",
    "    logger.debug(assigned_param_groups)\n",
    "\n",
    "    weight_decay = optimizer_kwargs.get(\"weight_decay\", 0.0)\n",
    "\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": list(param_groups[\"groupA\"].values()),\n",
    "            \"weight_decay\": weight_decay,\n",
    "            \"lr\": lr,\n",
    "        },\n",
    "        {\n",
    "            \"params\": list(param_groups[\"embedding\"].values()),\n",
    "            \"weight_decay\": weight_decay,\n",
    "            \"lr\": loraplus_lr_embedding,\n",
    "        },\n",
    "        {\n",
    "            \"params\": list(param_groups[\"groupB\"].values()),\n",
    "            \"weight_decay\": weight_decay,\n",
    "            \"lr\": lr * loraplus_lr_ratio,\n",
    "        },\n",
    "        {\n",
    "            \"params\": list(param_groups[\"groupB_no_decay\"].values()),\n",
    "            \"weight_decay\": 0.0,\n",
    "            \"lr\": lr * loraplus_lr_ratio,\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    optimizer = optimizer_cls(optimizer_grouped_parameters, **optimizer_kwargs)\n",
    "    if optimizer_cls.__name__ == \"Adam8bit\":\n",
    "        import bitsandbytes\n",
    "\n",
    "        manager = bitsandbytes.optim.GlobalOptimManager.get_instance()\n",
    "\n",
    "        skipped = 0\n",
    "        for module in opt_model.modules():\n",
    "            if isinstance(module, nn.Embedding):\n",
    "                skipped += sum(\n",
    "                    {p.data_ptr(): p.numel() for p in module.parameters()}.values()\n",
    "                )\n",
    "                logger.info(f\"skipped {module}: {skipped/2**20}M params\")\n",
    "                manager.register_module_override(module, \"weight\", {\"optim_bits\": 32})\n",
    "                logger.debug(f\"bitsandbytes: will optimize {module} in fp32\")\n",
    "        logger.info(f\"skipped: {skipped/2**20}M params\")\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "optimizer = create_loraplus_optimizer(\n",
    "    opt_model=model,\n",
    "    optimizer_cls=torch.optim.AdamW,\n",
    "    optimizer_kwargs = {'lr': 1e-4, 'eps': 1e-6, 'betas': (0.9, 0.999), 'weight_decay': 0.0},\n",
    "    loraplus_lr_ratio=2.0, # Set to a max of 16. If it's a more simple training, move the value towards 1.\n",
    "    loraplus_lr_embedding=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "B3COkBi2Lx2x"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:236: UserWarning: You passed a `neftune_noise_alpha` argument to the SFTTrainer, the value you passed will override the one in the `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cd3853799d9410aab2974ad62727eb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9846 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b93f45d42b6477e95dc6aa961b9770d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/518 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:294: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "Using auto half precision backend\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "from trl import SFTTrainer\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    # peft_config=peft_config, #comment out if passing a peft model directly as 'model'\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=context_length,\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    train_dataset=data[\"train\"],\n",
    "    eval_dataset=data[\"test\"],\n",
    "    args=transformers.TrainingArguments(\n",
    "        max_steps=20, # comment this out after the first time you run. This is for testing!\n",
    "        save_steps=20, ### MAKE SURE TO CHECK THIS VALUE IS GOOD FOR YOUR RUN!\n",
    "        logging_steps=1,\n",
    "        num_train_epochs=epochs,\n",
    "        output_dir=save_dir,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        do_eval=True,\n",
    "        eval_steps=0.2,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        gradient_accumulation_steps=grad_accum,\n",
    "        log_level=\"debug\",\n",
    "        # optim=\"paged_adamw_8bit\",\n",
    "        # fp16=True, #For non-Ampere GPUs\n",
    "        bf16=True, # For Ampere GPUs\n",
    "        max_grad_norm=0.3,\n",
    "        lr_scheduler_type=\"constant\",\n",
    "        hub_private_repo=True,\n",
    "        # warmup_ratio=0.03, # optional, may help stability at the start of training. Not required for simple fine-tunes.\n",
    "        # optim=\"adamw_torch\", #comment out for LoRA +\n",
    "        # learning_rate=1e-4, #comment out for LoRA +\n",
    "    ),\n",
    "    callbacks=[logging_callback],  # Add custom callback here\n",
    "    optimizers=(optimizer, None),  # Comment in for LoRA+\n",
    "    neftune_noise_alpha=5 # Add in noise to embeddings to improve performance!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Currently training with a batch size of: 4\n",
      "***** Running training *****\n",
      "  Num examples = 9,846\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 8\n",
      "  Total optimization steps = 20\n",
      "  Number of trainable parameters = 73,654,272\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "844dbf7f46c24b14973cd628d2003980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112985966934098, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20240225_202605-5452v588</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/trelis/huggingface/runs/5452v588' target=\"_blank\">legendary-forest-173</a></strong> to <a href='https://wandb.ai/trelis/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/trelis/huggingface' target=\"_blank\">https://wandb.ai/trelis/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/trelis/huggingface/runs/5452v588' target=\"_blank\">https://wandb.ai/trelis/huggingface/runs/5452v588</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 03:32, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.205000</td>\n",
       "      <td>2.068762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.857500</td>\n",
       "      <td>1.969447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.943400</td>\n",
       "      <td>1.900053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.924600</td>\n",
       "      <td>1.863205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.899000</td>\n",
       "      <td>1.833468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 518\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 518\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 518\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 518\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 518\n",
      "  Batch size = 4\n",
      "Checkpoint destination directory ./results/deepseek-coder-1.3b-base_openassistant-deepseek-coder_1_epochs_4096_length-chat-fine-tuned-model/checkpoint-20 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Saving model checkpoint to ./results/deepseek-coder-1.3b-base_openassistant-deepseek-coder_1_epochs_4096_length-chat-fine-tuned-model/checkpoint-20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5919de875aa34a5ba5a8e7f886571cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/631 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--deepseek-ai--deepseek-coder-1.3b-base/snapshots/c919139c3a9b4070729c8b2cca4847ab29ca8d94/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 32013,\n",
      "  \"eos_token_id\": 32014,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5504,\n",
      "  \"max_position_embeddings\": 16384,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_key_value_heads\": 16,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 4.0,\n",
      "    \"type\": \"linear\"\n",
      "  },\n",
      "  \"rope_theta\": 100000,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.38.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32256\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/deepseek-coder-1.3b-base_openassistant-deepseek-coder_1_epochs_4096_length-chat-fine-tuned-model/checkpoint-20/tokenizer_config.json\n",
      "Special tokens file saved in ./results/deepseek-coder-1.3b-base_openassistant-deepseek-coder_1_epochs_4096_length-chat-fine-tuned-model/checkpoint-20/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=20, training_loss=1.9474931538105011, metrics={'train_runtime': 230.9597, 'train_samples_per_second': 2.771, 'train_steps_per_second': 0.087, 'total_flos': 4242861294845952.0, 'train_loss': 1.9474931538105011, 'epoch': 0.06})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the dictionary to reflect the final state of the model's parameters\n",
    "trainable_params_state_dict = {n: p.data for n, p in model.named_parameters() if p.requires_grad}\n",
    "\n",
    "# Save the final state of the trainable parameters (ONLY RELEVANT IF YOU HAVE SET EMBED AND NORM LAYERS TO TRAINABLE).\n",
    "final_save_path = os.path.join(save_dir, \"trainable_params_final.bin\")\n",
    "torch.save(trainable_params_state_dict, final_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vRkDOAXULhuB"
   },
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZZo5_-YXoAKt",
    "outputId": "11587512-7cfa-4436-c7b8-118a24c15c35"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.49.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (159 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.1/159.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading matplotlib-3.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (310 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.7/310.7 kB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.49.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.2.0 cycler-0.12.1 fonttools-4.49.0 kiwisolver-1.4.5 matplotlib-3.8.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "sVN2864jmzvA",
    "outputId": "abb2a93d-dfdc-4a36-f13a-377884ff36a3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAACHO0lEQVR4nO3de3xT9f348VfStOktvd+htJRLQe7IRWRTFBTxCt6dU5nOTUWdc9tvc5v378bU6Zw3vIv3u+D9AiLIuF/lXm6FAr0Xem/TJjm/P05Pmpbem+Qk6fv5eOTxIGmSfkIoeffzeV8MiqIoCCGEEEIECKPeCxBCCCGEcCcJboQQQggRUCS4EUIIIURAkeBGCCGEEAFFghshhBBCBBQJboQQQggRUCS4EUIIIURAMem9AG9zOBzk5+djsVgwGAx6L0cIIYQQXaAoClVVVaSlpWE0drw30+eCm/z8fNLT0/VehhBCCCF64MiRI/Tv37/D+/S54MZisQDqX05UVJTOqxFCCCFEV1RWVpKenu78HO9InwtutKOoqKgoCW6EEEIIP9OVlBJJKBZCCCFEQJHgRgghhBABRYIbIYQQQgSUPpdzI4QQIrDY7XYaGxv1XoZwg5CQkE7LvLtCghshhBB+SVEUCgsLKS8v13spwk2MRiMDBw4kJCSkV88jwY0QQgi/pAU2SUlJhIeHS2NWP6c12S0oKGDAgAG9ej8luBFCCOF37Ha7M7CJj4/XeznCTRITE8nPz8dmsxEcHNzj55GEYiGEEH5Hy7EJDw/XeSXCnbTjKLvd3qvnkeBGCCGE35KjqMDirvdTghshhBBCBBQJboQQQggRUCS4EUIIIfxcZmYmTz75pN7L8BkS3PgRm92Boih6L0MIIUQPGQyGDi8PPPBAj553w4YN/OY3v+nV2qZNm8Zdd93Vq+fwFVIK7id25lcw57nV/PaMLP5wbrbeyxFCCNEDBQUFzj+///773HfffeTk5Dhvi4yMdP5ZURTsdjsmU+cf1YmJie5dqJ+TnRs/8eW2AhpsDr7bWaT3UoQQwicpikJtg02XS1d31VNSUpyX6OhoDAaD8/qePXuwWCx8/fXXnHrqqZjNZv73v/9x4MABLrnkEpKTk4mMjGTixIksXbq0xfO2PpYyGAy8/PLLzJkzh/DwcIYMGcJnn33Wq7/fjz/+mBEjRmA2m8nMzOTxxx9v8fXnnnuOIUOGEBoaSnJyMpdffrnzax999BGjRo0iLCyM+Ph4ZsyYQU1NTa/W0xHZufETGw+dACC3tAab3YEpSOJSIYRwVddo55T7vtXle+96aCbhIe75SP3LX/7Cv//9b7KysoiNjeXIkSOcf/75/OMf/8BsNvPGG29w0UUXkZOTw4ABA9p9ngcffJBHH32Uxx57jKeffpprr72Ww4cPExcX1+01bdq0iSuvvJIHHniAq666itWrV3PbbbcRHx/P3Llz2bhxI3feeSdvvvkmp59+OsePH2flypWAult1zTXX8OijjzJnzhyqqqpYuXKlR9MsJLjxA1abna1HywFosDs4cqKOgQkR+i5KCCGERzz00EOcc845zutxcXGMGTPGef3hhx9m0aJFfPbZZ9x+++3tPs/cuXO55pprAPjnP//JU089xfr16znvvPO6vaYnnniC6dOnc++99wIwdOhQdu3axWOPPcbcuXPJy8sjIiKCCy+8EIvFQkZGBuPGjQPU4MZms3HppZeSkZEBwKhRo7q9hu6Q4MYP7DhWQYPN4by+v7haghshhGglLDiIXQ/N1O17u8uECRNaXK+uruaBBx7gyy+/dAYKdXV15OXldfg8o0ePdv45IiKCqKgoiouLe7Sm3bt3c8kll7S4berUqTz55JPY7XbOOeccMjIyyMrK4rzzzuO8885zHomNGTOG6dOnM2rUKGbOnMm5557L5ZdfTmxsbI/W0hVytuEHNjQdSWn2F1frtBIhhPBdBoOB8BCTLhd3dkqOiGj5y+sf//hHFi1axD//+U9WrlzJ1q1bGTVqFA0NDR0+T+vZTAaDAYfD0c69e8disbB582beffddUlNTue+++xgzZgzl5eUEBQWxZMkSvv76a0455RSefvppsrOzyc3N9chaQIIbv7Dx0HEAEiLVmRsS3AghRN+xatUq5s6dy5w5cxg1ahQpKSkcOnTIq2sYPnw4q1atOmldQ4cOJShI3bUymUzMmDGDRx99lG3btnHo0CGWLVsGqIHV1KlTefDBB9myZQshISEsWrTIY+uVYykf53AobDys7txcNr4/L/x4kAMlEtwIIURfMWTIED755BMuuugiDAYD9957r8d2YEpKSti6dWuL21JTU/nDH/7AxIkTefjhh7nqqqtYs2YNzzzzDM899xwAX3zxBQcPHuSMM84gNjaWr776CofDQXZ2NuvWreP777/n3HPPJSkpiXXr1lFSUsLw4cM98hpAdm583oGSasprGwkNNnLx2DT1tuJqaeYnhBB9xBNPPEFsbCynn346F110ETNnzmT8+PEe+V7vvPMO48aNa3F56aWXGD9+PB988AHvvfceI0eO5L777uOhhx5i7ty5AMTExPDJJ59w9tlnM3z4cJ5//nneffddRowYQVRUFD/++CPnn38+Q4cO5e9//zuPP/44s2bN8shrADAofexTsrKykujoaCoqKoiKitJ7OZ16Z10ef120nSlZ8bx+4ySG3/cNdofCur9OJzkqVO/lCSGELurr68nNzWXgwIGEhsr/hYGio/e1O5/fsnPj47R8m4mZsYSYjGTEhQOSdyOEEEK0R4IbH7fhsBrcTMhUmy4NSlJbc0twI4QQQrRNghsfVlhRz5HjdRgNMG5ADACDJbgRQgghOiTBjQ/b2LRrMzw1Ckuo2q9gcKIEN0IIIURHJLjxYdo8qYmZzXNAtGMpKQcXQggh2ibBjQ/bcEjLt2luUT0oUe1cWVxlpbK+UZd1CSGEEL5MghsfVVXfyO6CSgAmZDTv3FhCg0lpKgGXoynvsNrsfP5TPsdrOm51LoQQwjdIcOOjtuSV41AgPS6MlOiWtf7+mFSsKApWm13vZfTIp1vyuePdLcz/arfeSxFCCNEFugY38+fPZ+LEiVgsFpKSkpg9ezY5OTkdPuall17i5z//ObGxscTGxjJjxgzWr1/vpRV7j7O/jcuujUYLbg74UXBz8xsbOX3+Mipq/e8o7UCp+ve8Ke9EJ/cUQgjfcOjQIQwGw0mjFPoKXYObFStWMG/ePNauXcuSJUtobGzk3HPPpaampt3HLF++nGuuuYYffviBNWvWkJ6ezrnnnsuxY8e8uHLP0yaBT8g8Objxt1439Y12lu0ppqymgV1NR23+pKiiHoDc0hqqrTadVyOE8Hdz587FYDCcdDnvvPO8uo5p06Zx1113efV7eouugzO/+eabFtcXLlxIUlISmzZt4owzzmjzMW+//XaL6y+//DIff/wx33//Pddff73H1upNjXYHW45olVKxJ33dWQ7uJxVT+4qqcTQN+SiqrNd3MT1Q2LRmRYFd+ZVMGnhywCmEEN1x3nnn8dprr7W4zWw267SawONTOTcVFRUAxMV1/cOjtraWxsbGdh9jtVqprKxscfF1O/MrqW90EBMezKCmQMbVoCS1YurI8VrqG30/j2V3YfPfeaEfBjdFlVbnn7cfq9BxJUKIQGE2m0lJSWlxiY1Vf5n9xS9+wVVXXdXi/o2NjSQkJPDGG28A6ubAz372M2JiYoiPj+fCCy/kwIEDbl3jxx9/zIgRIzCbzWRmZvL444+3+Ppzzz3HkCFDCA0NJTk5mcsvv9z5tY8++ohRo0YRFhZGfHw8M2bM6PBUxt103blx5XA4uOuuu5g6dSojR47s8uP+/Oc/k5aWxowZM9r8+vz583nwwQfdtUyv0PJtJmTEYjQaTvp6YqSZqFATlfU2DpXVMCzFtweA7nY5iiqs8K/gRlGUFmveIcGNEL5LUaCxVp/vHRwOhpP/v+6Ja6+9liuuuILq6moiI9VfcL/99ltqa2uZM2cOADU1Ndx9992MHj2a6upq7rvvPubMmcPWrVsxGnu/b7Fp0yauvPJKHnjgAa666ipWr17NbbfdRnx8PHPnzmXjxo3ceeedvPnmm5x++ukcP36clStXAlBQUMA111zDo48+ypw5c6iqqmLlypV4c063zwQ38+bNY8eOHfzvf//r8mP+9a9/8d5777F8+fJ2p8Lec8893H333c7rlZWVpKen93q9ntTc36bt3SiDwcDgpEg255Wzv7ja54ObPQVVzj/727FUldVGncvumAQ3Qviwxlr4Z5o+3/uv+RAS0eW7f/HFF87AxfkUf/0rf/3rX5k5cyYREREsWrSI6667DoB33nmHiy++GIvFAsBll13W4rGvvvoqiYmJ7Nq1q1sbBO154oknmD59Ovfeey8AQ4cOZdeuXTz22GPMnTuXvLw8IiIiuPDCC7FYLGRkZDBu3DhADW5sNhuXXnopGRkZAIwaNarXa+oOnziWuv322/niiy/44Ycf6N+/f5ce8+9//5t//etffPfdd4wePbrd+5nNZqKiolpcfJmiKC6diU/Ot9H4Szm4oih+fSylJRMHB6m/kR0oqaa2QZKKhRC9c9ZZZ7F169YWl1tuuQUAk8nElVde6cwxramp4dNPP+Xaa691Pn7fvn1cc801ZGVlERUVRWZmJgB5eXluWd/u3buZOnVqi9umTp3Kvn37sNvtnHPOOWRkZJCVlcV1113H22+/TW2tums2ZswYpk+fzqhRo7jiiit46aWXOHHCu9Wmuu7cKIrCHXfcwaJFi1i+fDkDBw7s0uMeffRR/vGPf/Dtt98yYcIED6/Su3JLayiraSDEZGRkv+h27+cvwU1RpZVyl/LvIj87ltKCsayESE7UNlBcZWV3QSWntlGiL4TQWXC4uoOi1/fuhoiICAYPHtzu16+99lrOPPNMiouLWbJkCWFhYS2qqS666CIyMjJ46aWXSEtLw+FwMHLkSBoavNNs1GKxsHnzZpYvX853333HfffdxwMPPMCGDRuIiYlhyZIlrF69mu+++46nn36av/3tb6xbt67Ln/O9pevOzbx583jrrbd45513sFgsFBYWUlhYSF1dnfM+119/Pffcc4/z+iOPPMK9997Lq6++SmZmpvMx1dW+/SHfVdquzdj+MZhNQe3ez1+CGy3fJiZcHfxZXGXF7vDeuWtvafk2ydGhzmBz+1E5mhLCJxkM6tGQHhc35dtoTj/9dNLT03n//fd5++23ueKKKwgOVv8fLSsrIycnh7///e9Mnz6d4cOHu31nZPjw4axatarFbatWrWLo0KEEBamfTSaTiRkzZvDoo4+ybds2Dh06xLJlywA1fWLq1Kk8+OCDbNmyhZCQEBYtWuTWNXZE152bBQsWAGqtvavXXnuNuXPnAuoWm2ty1IIFC2hoaGiRlQ1w//3388ADD3hyuV7R1jyptmhVVAdLa7A7FILaSDz2BdqR1NRBCXy9owCbQ6Gs2kpSVNs5Ur5GyxFKiTKTEh3Gsj3F7Mj3/Yo7IYRvs1qtFBYWtrjNZDKRkJDgvP6LX/yC559/nr179/LDDz84b4+NjSU+Pp4XX3yR1NRU8vLy+Mtf/tKjdZSUlJzU6C81NZU//OEPTJw4kYcffpirrrqKNWvW8Mwzz/Dcc88Bas7QwYMHOeOMM4iNjeWrr77C4XCQnZ3NunXr+P777zn33HNJSkpi3bp1lJSUMHz48B6tsSd0P5bqzPLly1tcP3TokGcW4yM2Hj55Enhb+seGE2Iy0mBzcPRELRnxXU9k86bdTcnEI/tFs+HQcYqrrBRW1vtNcFPoDG5CGdW0cyNJxUKI3vrmm29ITU1tcVt2djZ79uxxXr/22mv5xz/+QUZGRov8F6PRyHvvvcedd97JyJEjyc7O5qmnnjppo6Ar3nnnHd55550Wtz388MP8/e9/54MPPuC+++7j4YcfJjU1lYceesi58RATE8Mnn3zCAw88QH19PUOGDOHdd99lxIgR7N69mx9//JEnn3ySyspKMjIyePzxx5k1a1a319dTPlMtJaCkykpuaQ0GA4wf0PHOTZDRQFZCBHsKqzhQUu2zwc2epmOpYakWUqJD1eCmop7RXcsb111hhdrjJikqlJH91GT0fcXV1DfaCQ1u/9hQCCHas3DhQhYuXNjp/YYPH97uJsCMGTPYtWtXi9tc75uZmdnpBkLrzYPWLrvsspOqsjQ/+9nP2n388OHDT2rS620+US0lVJsOq0dS2ckWoptyVDri63k39Y12DpaqTZtOSY0iuWm3xp/KwYtcdm5SokJJiAzB7lBa9O4RQgjhWyS48SEbnfOkOt610fh6cLO/uBq7QyE2PJgki5mUpuDGn8rBncdS0aEYDAZGpMnRlBBC+DoJbnzIhqZ8mwldLDP29eBGG5I5PDUKg8FASnRTcFNh7ehhPsNmd1Bara5V23VqzruRnRshhPBVEtz4iNoGGzubdgN6snPjzbbWXaV1JtY6KKf42bFUSbUVRVEb+MVHhAA4825kxpQQQvguCW58xNYj5dgcCqnRofSLCevSYzLjIzAaoLLeRkm17+2G7Hbu3Kjtwp07N34S3Gg9bpIsoc4ZX1qvm71FVVhtvj+0VIhA54u/2Imec9f7KcGNj2jOt4nD0MVmUKHBQaTHqV0xfe1oSlEU9hQ2H0tB89GOv3Qp1naYkqPMztv6xYQRGx6MzaGQU1jV3kOFEB6mNbTTWv6LwKB1WNYaBfaUlIL7CK15X0fzpNoyODGSw2W1HCip4fRBCZ0/wEuKKq2cqG0kyGhwHp9pOzdVVhs1VhsRZt/+56ft3GjrBrXr5sh+0azcV8r2YxWM7h+j0+qE6NuCgoKIiYmhuLgYgPDw8C7/Yih8k8PhoKSkhPDwcEym3n0++PanSx9hszvY3M1kYs3gpEi+31PMAR/budE6E2clRDj7wUSaTUSaTVRbbRRW1ju7LPuqwsqWycQaLbiRpGIh9JWSkgLgDHCE/zMajQwYMKDXgaoENz5gT2EVNQ12LGYT2SmWbj12kI9WTO0uaHkkpUmOMlNdYqOowveDm+ZjqVbBjZSDC+ETDAYDqampJCUl0djY2PkDhM8LCQlpMXKppyS48QEbm46kxmfEdntGlK+WgzsrpVJbBmsp0aEcKKnxi6Ri57FUq+BGKwfPKayiweYgxCSpa0LoKSgoqNc5GiKwyP/KPmCDc55U9/JtoHmAZmFlPVX1vvObS/s7N/5TMdXezk16XBhRoSYa7A72FklSsRBC+BoJbnSmKIpz52ZCJ8My2xIdFkyiRa3mOVBS49a19ZTr2IXhKS2DmxQ/qZhSFKVFd2JXWlIxwM58OZoSQghfI8GNzo6eqKOo0kpwkIExPay8GZzoW0dTrmMXXMuowX963VRbbdQ2qH1sWh9LQfPRlDTzE0II3yPBjc60EvCR/aIJC+nZmbGv5d1oR1LDUqJOynhvPpbyvaaDrrQjqahQU5vvywgZwyCEED5LghudbTik5dt0/0hKowU3B0p8JbhR81Ba59uA/xxLafOvWh9JabSdm90FldjsDq+tSwghROckuNGZM98mo/vJxBpncOMjOzdaZ+LWlVLQHCwUV9X7dFBQ2E4ysSYjLpxIswmrzcE+H/l7F0IIoZLgRkcnahqcH4ynuiG4OXy8lgabvgGDoijOY6lT2ti5SYg0E2Q04FCgtLrB28vrMu1Yqq18GwCj0cCINPX1Sb8bIYTwLRLc6GhTUwn4oMQI4iPNndy7fUkWMxazCbtD4VCZvhVTxVUnj11wFWQ0kNj0Wn05qVjrcdPezg00D9GU4EYIIXyLBDc62nBYmyfV83wbUEuTs3wkqVjbtXEdu9BaslYx5cN5N85jqXZybqA572ZHviQVCyGEL5HgRkeuk8B7y1fKwXc7OxOffCSlSWkqDy/y4Z2bzo6lAEb2U1/jrvxK7A7FK+sSQgjROQludFLfaGfb0XKgZ52JW/OVcnAtmXh4G8nEmhQ/6FLc3ugFVwMTIgkPCaKu0c5BH6lUE0IIIcGNbrYdraDRrpBoMTMgLrzXz+cr5eDOsQspHezcRIcBvlsObrM7KK1umgge3X4uVJBLUrE08xNCCN8hwY1OtOZ9EzNjez3aHVoGNw6djkisNrtzBERbZeCalGjfTigurW7AoYDJaCAhouNE7xFp0qlYCCF8jQQ3Omnub9P7fBuA9NgwQoKM1Dc6OFZe55bn7K59RerYhZjw4A6Pc3x9eKa2riSLGWMnU9q1pOKd0qlYCCF8hgQ3OnA4FDYe7n1nYlemICOZCerx1n6djqb2FDYlE6dYOtyN8vUuxc4y8A4qpTSuAzT12jETQgjRkgQ3OthbXEVVvY3wkKAOE2+7S+9Oxc58mw4qpaC5S3FNg52q+kaPr6u7ulIppRmUGEFosJGaBju5OvcYEkIIoZLgRgfaPKnxA2IxBbnvLdC7HNxZKdVBMjFAeIgJS6gJ8M1y8M5GL7gyBRmdwZw08xNCCN8gwY0OnPk2bigBdzVIx3JwdexC+wMzW3OWg1f43nTwoi50J3Y1SjoVCyGET5HgRgfO5n1uSibW6FkOXlJl5XhNA0YDDEk+eexCa9rRlC8mFWtrSumgDNyVlncjFVNCCOEbJLjxsmPldRwrryPIaGDsgBi3PvegxEgMBjhR20hZtXd3RHZpYxcSI9sdu+BK2xXx92MpgJFpzRVTklQshBD6k+DGy7QjqVNSo4g0m9z63KHBQfSPVRvkeftoyrVSqiuaj6V8L7gp6kJ3YldDkiMJMRmpstrIO17ryaUJIYToAgluvEybBO7ufBvNIC2p2MtHU12tlNIk++ixVLXVRk2DHWg+OutMcJCR4U1BnRxNCSGE/iS48TKtUspd/W1a06tiao8zmdi/d2609VhCTYSHdH1nbaRzQrgEN0IIoTcJbryosr7RWS49IcMzOzd6DNBUxy6o36+rOze+OjyzOz1uXI2UiikhhPAZEtx40ebDJ1AUyIgPJ6mbH55dpUcjv/3F1dgcCtFhHY9dcKUNpCytttJod3hyed3inAbexSMpTXM5eCWKIknFQgihJwluvMhTJeCutOAmv6KeGqvNY9/H1W6XI6muDgFNiDBjMhpQFLWM3Fc0z5XqXnAzNNlCcJCBirpGjp7QZ7aXEEIIlQQ3XuQ6CdxTYsJDSIgMAeBgiXfGAexpSiYe1klnYldGo4Eki+9NBy/qZo8bTYjJSLYkFQshhE+Q4MZLGmwOth4pB2CCh5KJNc0VU1Ue/T6a3U15RKd0Md9Go1VM+dIAzcJuloG7kk7FQgjhGyS48ZId+RVYbQ5iw4MZlBjh0e/lzTEMrmMXhnVzCKgvJhUXdbOBn6sRadKpWAghfIEEN17SPE8qrst5KT3lzXJw17ELQ5O7F9wk+2Bw0zx6oec7NzvzJalYCCH0JMGNlzT3t/Fcvo3Gm+Xgu5s6Ew9MiOjS2AVXqT52LGV3KM7k5p4cS2WnWDAZDRyvaSDfR16TEEL0RRLceIGiKC12bjxNC24Ol9V6vMy6u52JXfna8MzSaisOBYKMBuIju5dQDOr4iyFNu1eSdyOEEPqR4MYLDpTUcKK2EbPJ6Byy6Emp0aFEhARhcygcLvNsxdSeXgQ3zcMzfaMUXEsmTrKYCTL27OhwVD/170GCGyGE0I8EN16g7dqMTY8hxOT5v3KDweCSVOzZ4GZ3N8cuuHIdweALOSrdnQbeFulULIQQ+pPgxgs8PU+qLVpS8QEPDtB0HbvQnR43Gu1Yqq7RTmW9dxoOdqS5Uqr7R1IaLbjZLp2KhRBCNxLceMHGw1q+jeeTiTXeKAd3HbuQ2oPqotDgIKLDgoHmwEJPvelxoxmeEoXRoObv+MpxmxBC9DW6Bjfz589n4sSJWCwWkpKSmD17Njk5OR0+ZufOnVx22WVkZmZiMBh48sknvbPYHiqurOdwWS0GA4z30LDMtgzyQjm4Ngl8WErXxy605kvTwZ3HUj0I1DRhIUEMSZKkYiGE0JOuwc2KFSuYN28ea9euZcmSJTQ2NnLuuedSU9N+nkhtbS1ZWVn861//IiUlxYur7ZmNh9UjqWEpUUSFBnvt+zoHaJZU43B45nikN5VSmmQfqpjq6UTw1kY0JRVLMz8hhNCHSc9v/s0337S4vnDhQpKSkti0aRNnnHFGm4+ZOHEiEydOBOAvf/mLx9fYW96YJ9WWjPhwTEYDtQ12Cirr6RcT5vbvsaew58nEmpSm/BZf6HXjjmMpUJv5fbL5GDvzJbgRQgg9+FTOTUWF+mEQF+e+xFur1UplZWWLizc5J4F7MZkYIDjISGaCOubBE0dT6tiF3u/c+NIIBi1HpjfHUtDcqVh2boQQQh8+E9w4HA7uuusupk6dysiRI932vPPnzyc6Otp5SU9Pd9tzd6baanP+9u7tnRtwqZjyQHBTUm2lrIdjF1w5j6V03rmpttqotqoVW73duRmeGoXBoAZLxVX6B21CCNHX+ExwM2/ePHbs2MF7773n1ue95557qKiocF6OHDni1ufvyNa8chwK9IsJIzXa/cdCnRmU1LRz44FycK2/TU/GLrjylZ0bLd/GYjYRYe7daW2E2eRM6N55zLs7hUIIIXwkuLn99tv54osv+OGHH+jfv79bn9tsNhMVFdXi4i165dtoPDljSutMPKwXR1Lg2qVY5+CmoveVUq5GpklSsRBC6EXX4EZRFG6//XYWLVrEsmXLGDhwoJ7LcTutv82pXs630QxOVI+LPHEspeXbnNLL4EZr5Fda3UCDzbNzsDpS6KZKKY10KhZCCP3oWi01b9483nnnHT799FMsFguFhYUAREdHExamHuNcf/319OvXj/nz5wPQ0NDArl27nH8+duwYW7duJTIyksGDB+vzQtrQaHewJa8c0G/nRjuWKqtp4ERNA7ERIW57bq1SalhKz/NtAOLCQwgOMtBoVyiuqqd/bLg7ltdtWnCT1IvuxK4kuBFCCP3ounOzYMECKioqmDZtGqmpqc7L+++/77xPXl4eBQUFzuv5+fmMGzeOcePGUVBQwL///W/GjRvHr3/9az1eQrt2F1RS22DHEmpiaFLvAoCeCg8xOUvA3Zl3Y7XZnUddvamUAjAaDSRZ9D+aKnJTGbhmRNOxVH5FPWXV0qlYCCG8Sdedm67M3lm+fHmL65mZmX4xs0ebJzUhIxZjDydMu8OgpEiOldexv7jabbOtDhTXYHMoRIWaejR2obWU6FCOlddRWKFfEOA8lnJTzo0lNJishAgOltawI7+SM4cmuuV5hXC15kAZQ5IjSYh0z46jEIHCJxKKA5E2Cdzb/W1a80Q5uGt/m56OXXDlCxVThVqPGzft3ACMkKMp4UE/7i3hmpfWcutbm/ReihA+R4IbD1AURZdJ4G3xRDn4nsLeN+9zpe2WBNKxFMCopjEMEtwIT/hmp5qjuOHQCQ56oN2DEP5MghsPOFxWS2m1lZAgI6P7R+u6lsEeGKCp9bjpzdgFV3oPz7Q7FEqa8mLcdSwFMDJNOhULz1AUhRU5Jc7ri7fm67gaIXyPBDceoPW3GdU/ulcN7txB63VzrLyOuga7W55T27kZluKenRu9h2eWVVuxOxSCjAa35i5ox1JHT9RRXtvgtucVYn9xNcfK65zXF2855he5iEJ4iwQ3HrDpsDZPSp8ScFfxkWZiw4NRFHVCeG8VV9VTWt37sQuuUnRu5KcFVYmRZoLcmPwdHRbMgDi1tH2HdCoWbrS8addmYmYs4SFB5B2vZXNT6wkhhAQ3HuHsTJyhb76NRtu9cUdws6fpSCozIYKwEPfsSrkeS+nx22ehm7sTu9KGaO6QCeHCjZbvLQbgvJGpnDciBVB3b4QQKglu3Kys2sqBkhoATs3Qf+cG3DuGwR2TwFvTGudZbQ4q6hrd9rxdpe0YJVvcX047UiaECzersdrYkKvuDk/LTmT2uH4AfLEtX9cu30L4Eglu3Ew7khqSFOnWjsC9MciNScVaZ+LhvexM7Co0OIjY8GBAn7wbd/e4cTWyqWJqpwQ3wk3WHCijwe4gPS6MrIQITh8UT6LFzInaRn7cW9L5EwjRB0hw42Ybnfk2vnEkBWojP3DPsZQndm6gub+MHhVTWvNAd/a40WgVU4fKaqms9/6ulAg82pHUtKFJGAwGTEFGLh6TBsCirXI0JQRIcON2ek8Cb4tWDp5bWoPN3vNt6wabwxkgdXsaeO1xsLVfMaRnr5siNw/NdBUbEeIcgSH9bkRvKYriTCaelt3c9XpO09HUkl1FEkQLgQQ3blXXYHd+gOndvM9Vv5gwwoKDaLQr5B2v7fHzHCipptGujl1I6+4Rzqe3w/NT4eCKNr+sBRYFeuzcePBYCpqTindKxZTopQMlNRw9UUdIkJEpg+Kdt49Ii2JwUiQNNgffbC/UcYVC+AYJbtzop6PlNNoVkqPM9I8N03s5TkajgazEpk7Fvci70Y6khnV37EJVERzdAKV74Y2L4eNfQ1XL/4CTdSwH17oTe+JYCprzbiSpWPTW8hz1SGpyVhzhIc2jAQ0Gg3P3ZpFUTQkhwY07uc6TcsfMJXdyVkz1Iu+mx8nElmS4fQNM+g0YjLD9Q3hmIqx9Huw2oHnXxNs5NzVWG1XWlmtwt5FSDi7cZEVTwnBbg1i1vJu1uWXkuzT4E6IvkuDGjZzzpHykBNyVO8Yw9CqZOCwGzn8Mbv4B+p0K1kr45s/w0jQ4ssFleKZ3J4NrO0WRZhORZlMn9+4ZLbjJLa2huimQEqK7ahtsrDuo/gLlmm+jSY8LZ1JmHIoCn/0k4xhE3ybBjZvYHQqbfbBSSuNs5Ner4Ebduel2MrGrtLFw01K48EkIjYHC7fDKDMZuvY8Yqrx+LKXl2yRHub/HjSYh0kxqdCiKArvyJe9G9IxWAt4vJszZ3qE1reeNNPQTfZ0EN26SU1hFldVGpNnEMDf2gHGX5nLwmh51AS6pslJabcVggOzejl0wGmHCr+COTTDulwDE7nmXZeY/cE79t1gbvVft4Wzg56F8G4008xO9pR1JTctObPfY+4JRqYQEGdlTWOXcaRWiL5Lgxk2GJEeyeN5UHr18NKYg3/trzYyPIMhooNpqo6gHRz/asMyB8e4bu0BEAlzyLNz4LUryCOIM1TwS/BK8MhMKtrnne3RC63HjiTJwV1q/GykHFz3RsgQ8qd37RYcHc9Yw9chKdm9EX+Z7n8J+KjjIyNj0GM4flar3UtoUYjKS0TTEsSd5N55q3gfAgNMw/OZHngq+kWolFHPhJnjxTPj6z1Dv2WDAuXPjoWRizaj+6t+bBDeiJ3JLa8g7XktIkJHTXUrA2zJnXH8APt2aj90hk8JF3yTBTR8yyDljqqrbj9UGZnrsyC3IxMr4K5hu/TfH+s0CxQHrnlerqrZ/BB4aqKlVZ3lr5+ZASTW1DZJULLrHOQV8YCwRnSS+nzUskahQE4WV9aw7WOaN5QnhcyS46UN6Uw6+y5M7N01SosMoIo6vh/0TrlsM8YOhugg+vglevwhKctz+PQu9lHOTFBVKksWMQ0FyIUS3LdfybYa2fySlMZuCuGB00zgGOZoSfZQEN31IT8vBW45d8FyydEpTxVJhRT0MOgtuXQ1n/x1MoXBoJSyYCksfhIaed1lurcjD3YldOZOKj8rRlOi6ugY7a5t2YNoqAW+L1tDv6x2F1DfaPbY2IXyVBDd9SPOxVE23HqeNXbCEmpxzkjzBOTxTKwc3meGMP8G8dTD0PHA0wv+egGcnw56vev39HA6F4irvJBSDazM/2bkRXbf2YBkNNgdp0aHO3dfOTMiIpV9MGNVWG0t3F3l4hUL4Hglu+pBBTSMYSqutVNR2vdxaq5QantLNsQvd1O7wzNhM+MX7cPW7ED0AKvLgvWvgnavgxKEef7/SGit2h4LRAAmRIT1feBdpM6YkqVh0hzZy4czspC7//BmNBmaPU4+mpGpK9EUS3PQhltBg5w5Fd/JutOZ9wz14JAW4dClup5HfsPPVXZyf/wGMwbD3G3UX58fHwNb98vaipjLwRIvZK+X72oypfcXVclQgusy1v013zB6rHk0tzymhrNq7nb+F0JsEN31MTzoVuw7M9KTm4ZnW9hsNhoTD9PvUfJyBZ4CtHpb9Hyw4HQ4s69b381YysSYlKpSEyBDsDkWSikWXHCqt4VBZLcFBBqYOTujWY4ckWxjZLwqbQ+HL7QUeWqEQvkmCmz6mJxVTzTs33gluGmwOTnR2bJY4FK7/DC57BSKToWw/vDkHPvwVVHZtro63gxuDwcAIaeYnukE7kpqQEdej2Wfa7o1UTYm+RoKbPqY5qbhrwY3r2IWhyV1LZuypEJOR+Ag196VL08ENBhh1uTpxfPKt6sTxnZ+ovXHWPOucON6eIi/1uHHVnHcjOzeic8t7eCSluXhMGkYDbMkr51Bp9woJhPBnEtz0Md0tB3cduxAe4pmp2a6aj6a6MUAzNBpm/Qt+swL6T4KGavj2r2qX47y17T6s0Itl4Bot70ZmTInO1DfaWXNAKwHvvL9NW5KiQp3HWYu3yu6N6DskuOljBiWpFVNHTtR2KanV2ZnYw8nEGi3QKOjKzk1rqaPhxm/h4qchLA6KdsCrM2HxPKgpPenu3hqa6UorB99bVIXVJknFon1rD5ZhtTlIjQ7t1a7ppeObJ4X3ZGiuEP5Igps+JjHSTFSoCUWBgyWdb1M7Z0qleDbfRnNSr5vuMhph/PXqxPHxN6i3bX0Lnj4VNr4KDofzrt4aveCqX0wYseHB2BwKOYXdH4Mh+g5t5MKZQ9ufAt4V556SQlhwEIfKatl6pNxNqxPCt0lw08cYDIbmiqkuJBXvLtR2brwT3GiBRlFPdm5chcfBxU/BTUshZRTUl8MXv4dXZkD+FsD1WMrcu+/VDQaDobmZn+TdiA70tAS8tQiziZkjkgHpeSP6Dglu+qDBXUwqbrA5nEM2Pd3jRqMFGj3euWktfSLcvBxmPQrmKDi2CV46m8bP78bQNHHcm8dS4DKGQfJuRDsOl9WQW1qDydj9EvC2zG4ax/D5tgIa7Y5O7i2E/5Pgpg/qajn4wVLvjF1w1aOE4s4EmWDyb9WqqlFXgOIgeNMrfG/+A1eFrMbSgxLb3hgp5eCiE9quzakZsVhCg3v9fD8bnEBCZAjHaxpYua+k188nhK+T4KYP6mojP9d8G0+OXXClJRS7befGlSUFLnsZrv+M2qhBJBoqecT4DCy8EIp3u//7tUMrB88prKLBJr9Fi5Np+TY9rZJqzRRk5KIx2qTwrvWBEsKfSXDTBw1OVI+YDpbWYHe0Xz3h7UopaM65Ka9t9NyIgqwzWXLmxzzSeDVWgxkO/w+e/xksuQ+s3ZuY3hPpcWFEhZposDvYWyRJxaKl+kY7qw+o1X29zbdxpU0K/25nIVX1XZ8tJ4Q/kuCmD+oXG0aIyUiDzcGR47Xt3m+XtnPjpWRigOiwYMwm9Z+lW4+mWimodrDAfjGPDHoDhl0IDhus+i88Owl2fQYeLJl1TSremS9HU6Kl9bnHqW90kBIVyrAU9/1iMapfNFmJEVhtDr7dKZPCRWCT4KYPCjIayEpQ+910lFS8R6uUcuN/sJ0xGAzNR1O9rZjqgPbcIfGZcPXbcM37EDMAKo/BB9fB21fA8YMe+/6jJKlYtMNdJeCtGQwG5oxt7nkjRCCT4KaP6qwcvLTaSkmVOnYh24vBDbih100XaLtCKVFNZeDZ58G89XDG/4OgENi/BJ49DZb/Cxrdv44RUg4u2rF8rzpP6kw3HklpLmkKblYdKPXoLw9C6E2Cmz6qs3JwLd8m00tjF1ylRnugYqqVNkcvBIfB2X+DW9dA1llgt8Ly+fDcabBvqVu/v7Zzs7ugEpuU5oomR47XcrCkhiA3lYC3NiA+nAkZsSgKfPaT7N6IwCXBTR/VWTm4s1LKi8nEGi2puLDC6rHvoTUJbLPHTcJguG4RXLEQLKlwIhfevgzevw4qjrrl+2fEhRNpNmG1OdjXxTlfIvBpgzJPHRBLdFjvS8DbovW8kaopEcgkuOmjXHdu2po3s7tpYOYwL41dcOWRXjcuHA6F4io1cGp3aKbBACPmqL1xptwOhiDY/Rk8MwlWPQX23lWbGI0GRqSpf7fS70ZoVuR47khKc+HoVIKDDOwuqHQOxhUi0Ehw00dlxkdgNEBVvY2SqpN3SHYXaJ2JvR/ceLTXDVBW04DNoWAwqLO2OmS2wMx/wC0rIf00aKyBJffC8z+HQ6t6tY7mMQwS3Aiw2uysdk4B91xwExMewllN/XMWy+6NCFAS3PRRocFBpMeFAyfn3TTam8cueLNSSuNMKPZQwqO2I5QQacYU1MUfgeQR8Kuv4ZLnIDweSnbDwvNh0S1QXdyjdWh5Nzvy5bdnARtyT1DbYCfJYuYUD/9SofW8+XTrMRwd9LoSwl9JcNOHDU5sO+/mQEnT2AWzif6x3hm74ErbuSmuqvfIf7w9ngZuNMK4a+H2jTDhRsAAP70LT0+A9S+Bo3tNB7Wdm135lR02UxR9w3LtSMrNJeBtOWtYEpZQEwUV9azLPe7R7yWEHiS46cPaG8Pg2pnYW2MXXCVZzBgM0GhXOF7b4Pbn1467ejwwMzwOLvwP3Pw9pI4FawV89Ud46Wx1MGcXDUyIIDwkiLpGOwe7MKFdBLble907cqEjocFBXDAqFZCeNyIwSXDThw1qp2Jqtw6diV0FBxmJj2iaDu6Boylnj5voTvJtOtPvVLh5GZz/bzBHQ8FWeGk6fPF7qDvR6cODXJKKpZlf33b0RC37i6sxGtQhl96gVU19tb3Ac6NOhNCJBDd9WHu9bnY7OxPrE9xAc+DhieCmx8dSbTEGwaSb4Y6NMPpqQIGNr6pHVVve7nSMw4g06VQsmrsSjx8QS3S4Z0rAW5uUGUdadChVVhvL9vQsb0wIX6VrcDN//nwmTpyIxWIhKSmJ2bNnk5OT0+njPvzwQ4YNG0ZoaCijRo3iq6++8sJqA8+gppybokorlS6D9PTscaNJ8WCX4l4fS7UlMgkufQHmfgmJw6C2FD69DV6bBUU7232YllS8UzoV92krnEdSnquSas1oNHCJs+eNHE2JwKJrcLNixQrmzZvH2rVrWbJkCY2NjZx77rnU1NS0+5jVq1dzzTXXcNNNN7FlyxZmz57N7Nmz2bFjhxdXHhiiw4JJtKg7JFrejZ5jF1x5stdNUVvdid0l82dwy//gnIcgOBzy1qhl49/+DawnTwB3HaApVSt9U4PNwer92hRwz+fbuNKqppbnFHOixv35bULoRdfg5ptvvmHu3LmMGDGCMWPGsHDhQvLy8ti0qf2kzP/+97+cd955/OlPf2L48OE8/PDDjB8/nmeeecaLKw8czoqppuBGz7ELrlI8WA5eVGlt8T3cLigYpv5ObQA4/GJQ7LDmGXhmIuxc1OKoalBiBKHBRmoa7OSWtR/Ui8C18dBxahrsJER6vgS8taHJFk5JjaLRrvDl9gKvfm8hPMmncm4qKtS8g7i4uHbvs2bNGmbMmNHitpkzZ7JmzZo272+1WqmsrGxxEc1aj2HY4+xMrN+uDUCyhxr51TfaqahrbPE9PCa6P1z1Jlz7EcQOhKoC+HAuvDkHSvcDYAoyOj/QfjpS7tn1CJ+kVUmdOTQRo9H71Ylz5GhKBCCfCW4cDgd33XUXU6dOZeTIke3er7CwkOTk5Ba3JScnU1hY2Ob958+fT3R0tPOSnp7u1nX7u+ZycHXXYJfOlVKaFA8dS2k7QWHBQVjMXtqZGnIO3LYWpt0DQWY4+AMsmALL/gGNdUwcqAbzK/eVemc9wqdo/W28mW/j6uKxaRgNsOnwCfLKanVZgxDu5jPBzbx589ixYwfvvfeeW5/3nnvuoaKiwnk5cuSIW5/f3zmDm5KWx1J679w4RzC4+VjKdRq4V3v4BIfCtL/AbWtg8AywN8CPj8Kzk5kdoSYc/7i3RPJu+pj88jr2Fqkl4D8f4p0S8NaSo0KdE8gXb5XdGxEYfCK4uf322/niiy/44Ycf6N+/f4f3TUlJoaioqMVtRUVFpKSktHl/s9lMVFRUi4topgU3h8tqqLHanLk3eu/caAnFlfU26hrc14OjyFkp1cseNz0VP0g9prryTYjqB+WHGb7sJl4x/wdzTb6UhPcxWgn42PQYYsJDdFvH7LHq0dTiLcfaHKQrhL/RNbhRFIXbb7+dRYsWsWzZMgYOHNjpY6ZMmcL333/f4rYlS5YwZcoUTy0zoCVZzFjMJhwKfL+nmAa7g0idxi64igo1ERYcBLg378atPW56ymCAUy6Geevh9DvBaGK6YQNLzX+i6vvHwCZVK31F85GUd6ukWps5MoXQYCMHS2vYdlQCbOH/dA1u5s2bx1tvvcU777yDxWKhsLCQwsJC6urqnPe5/vrrueeee5zXf/e73/HNN9/w+OOPs2fPHh544AE2btzI7bffrsdL8HsGg4Gspt2bL35SJwQPS9Fn7IIrg8HgkaMpZ48bTycTd4U5Es59GG75H8VxpxJusPKzQ8/A8z+D3B/1Xp3wsAabwytTwLsi0mzi3FPU3W9JLBaBQNfgZsGCBVRUVDBt2jRSU1Odl/fff995n7y8PAoKmksUTz/9dN555x1efPFFxowZw0cffcTixYs7TEIWHdPKwbUtcr2PpDSeSCp29rjRc+emtaTh2K//gt833EqpEgWlOfD6RfDxzVBV1PnjhV/adPgE1VYbCZEhjGzqVK0nrWrq85/yabQ7dF6NEL2jXyMT6NLZ7vLly0+67YorruCKK67wwIr6Ji3vpqHpP7RhOnYmdpXigXJwnziWakNqTDi7Es/n7KLxLB7+A1m578L2D2DvN3D232HCTRCk64+rcLPle9UjqTOG6FMC3trPhiQQHxFCWU0D/9tfylk6H5UJ0Rs+kVAs9KUFNxpf2blJ9kAjP62Bn08cS7UyLTuRSiJ4JvS38JsfIG08WCvh6/8HL50FRzbovUThRiuadkrP1PlIShMcZOSiMWmATAoX/k+CG9EiuDEYIDvZR3Zumiqa3HUs5XAoFFf55s4NNH/IrdhbgiNlLPx6KVz4HwiNgcJt8MoM+OxOqD2u6zpF7xVU1LGnsAqjQd258RXapPBvdxZSbbXpvBohek6CG0F6bBghQeo/hYy4cCK81dyuE+4+ljpe20CjXcFgwDlTy5dMyIgjIiSIspoGduRXqBPHJ9wIt2+Esdeqd9r8Ojx9Kmx+AxySF+GvtF2bMekxxEboVwLe2pj+0QxMiKC+0cF3O9tujCqEP5DgRmAKMjIwIQKAYSm+cSQFLsMz3XQspR1vxUeYCQ7yvX/6ISajs5maltwNQGQizH4OfvUNJJ0Cdcfhszvg1ZlQuF2n1Yre0N7fM4f6zq4NqFWKWs8bqZoS/sz3/ocXuhiSrB5NnZLmO8GNtnNTXGXF7obOvc3TwH1v10aj9TvR+p+0kDEFfvsjnPsPCImEo+vhhTPg679AvcxM8xeNdgerdJoC3hWzx6l5N6v2l1Ls5vEnQniLBDcCgDvOHsLc0zP5xeQBei/FKTHSjNEANodCWbW1189X6Itl4K1o/U62HimnvLaNZn5BwXD67erE8RFzQHHAugXqxPHtH7WYOC580+bDJ6iy2oiLCGF0P/1LwFvLiI/g1IxYHAp81tT7Sgh/I8GNACA7xcIDF48gIdJ3djVMQUbnetyRd6MdbyX7cHCTFhPG0ORIHAr82NEgzag0uGIh/PITiBsE1YXw8U3wxsVQstdr6xXdp00BP2NIgk+UgLdltkwKF35Oghvh09zZpdgfdm6gk6Op1gZPV4dxnvV3MIWqnY0XnA7fPwQNMuHZF2n5Nr54JKW5cFQqJqOBnfmV7C2q0ns5QnSbBDfCpyW7sUtxoQ/3uHE1rSnJtMtTwk1mOPNPcNtaGDITHI2w8nF4djLs+crDqxXdUVRZz+6CSgwGOMPHkoldxUaEOI9Iv9khVVPC/0hwI3yatsvizmMpX9+5mZCploSXVjewM78bicJxA+EX78PV70B0OlTkwXvXwDtXw4lDHluv6DqtBHx0/xjifKgEvC2nZcUDsLtAktWF/5HgRvi05mOp3icUF2kN/Hx85ybEZOR0Z0l4F46mXBkMMOwCmLcOfvZ7MAbD3q/V3jgf3Qh5ayXpWEfayIVpPrxroxna1MwzR46lhB+S4Eb4NHcdS9U32imvbWzxnL5MOxLQkk+7LSQCZjwAt66CrGngsMGOj9XeOC+cAVvegsY6t61XdM5md7CyKUncV0YudCQ7RQ1uDpXWUN9o13k1QnSPBDfCp7nrWEoLjkKDjUSF+kYH5o5oyaZb8k60XRLeVYnZcP2nan+ccb9Uk44Lt8Gn8+CJU2DpA1B+xD2LFh3anFdOVb2N2PBgxvSP0Xs5nUqymIkOC8ahwIGSar2XI0S39Ci4OXLkCEePHnVeX79+PXfddRcvvvii2xYmBDQ33Ottl2LXaeAGg2+W37rq51ISvrKjkvCuSh0DlzwLd++GGQ9C9AC10/H//gP/HQ3vXatWWsmRlcesaDqS+vmQRIJ8tATclcFgcM6Zk4op4W96FNz84he/4IcffgCgsLCQc845h/Xr1/O3v/2Nhx56yK0LFH2bdoRUZbVR04tBftrOjz8cSWmaS8J7eDTVlvA4+Nld8LutcNXbMPAMtRHgni/g9YvUMvKNr0JDjfu+pwBcS8B9/0hKMzRF7VyeUyg7N8K/9Ci42bFjB5MmTQLggw8+YOTIkaxevZq3336bhQsXunN9oo+zhAYTERIE9O5oqnn0gh8FN0NdpoS7YfxEC8YgGH4h3PC5WkI+4SYIjoDiXfDF7+Hx4fDNX+H4Qfd+3z6quKreWfnmyyXgrcnOjfBXPQpuGhsbMZvV44KlS5dy8cUXAzBs2DAKCgrctzohaA5IenM0pVVb+XoZuKvmknAruzxZjps0HC58Au7eBTPnQ1wWWCtg7bPw1Hh4+0rYt1SmkPdCcwl4tE91Ae9MdtMg3ZxCCW6Ef+lRcDNixAief/55Vq5cyZIlSzjvvPMAyM/PJz4+3q0LFMJZDu6GnRt/OpbqVUl4T4TFwJTb4PZN8IsPYfA5gAL7voW3L4NnJ8La52VIZw9oVW/+UALuamjTQN1j5XVU1TfqvBohuq5Hwc0jjzzCCy+8wLRp07jmmmsYM2YMAJ999pnzuEoId0l2Q8VUoR8eS4FLSbg78246YzTC0HPhlx/BHZth8q1gjoKy/fDNn+GJ4fDlH6Ekx3tr8mM2u4OVTcHNmT48cqEtMeEhJEepO037iiXvRviPHtXETps2jdLSUiorK4mNjXXe/pvf/Ibw8HC3LU4IaD5K6t2xlP/t3EBzUvHmvBNU1DYSHR7s3QXED4JZ/4Kz/w7b3oN1L0JpDmx4Sb1kTYNJv4WhM9U8HnGSrUfKqay3ER0WzNj0GL2X021Dky0UVVrZW1jF+AGxnT9ACB/Qo52buro6rFarM7A5fPgwTz75JDk5OSQl+ddvJsL39fZYSlEUiv2kO3Fr/WLCGJLUVBK+34u7N62ZI2Hir9XOx9d/CtkXgMEIB5erIx6eGgur/gu1x/Vbo4/Sdt1+PiTBL0rAW8uWTsXCD/UouLnkkkt44403ACgvL2fy5Mk8/vjjzJ49mwULFrh1gUI0H0v1bATD8ZoGGu1qtVGiHyVzanQ5mmqPwaDu1lzzDty5Fab+DsJioTwPltynNgb87A4o3KH3Sn3Gir2+PwW8I0NTpGJK+J8eBTebN2/m5z//OQAfffQRycnJHD58mDfeeIOnnnrKrQsUwtmluKJn4wK0HZ+EyBBCTP7XlFv7UPRISXhvxGbAOQ/B73fBxU9D8iiw1cHmN+D5qfDa+bBzMdj7biJqSZWV7ccqADjTz5KJNc6dG+l1I/xIj/6nr62txWJR/8F/9913XHrppRiNRk477TQOHz7s1gUKoR0llVRZsdm7X47sj5VSriZkxhIeEkRJlYdLwnsqJBzGXw+3rIRffQ0j5oAhCA6vgg9vgCdHw4+PQbUP7Dx52Y9NuzYj+0WRaPG/XUOAIU0VU6XVVsqqez/AVghv6FFwM3jwYBYvXsyRI0f49ttvOffccwEoLi4mKirKrQsUIiHSTJDRgEOB0uruz1nyxx43rsymIE4f5MWS8J4yGCDjdLhiIfx+B5zxJ4hIhKp8WPZ/8J9TYNEtcGyT3iv1muYScP88kgIIDzExIE4tFJG8G+EvehTc3Hffffzxj38kMzOTSZMmMWXKFEDdxRk3bpxbFyhEkNHgzJXpSVKxc/SCnyUTu/KpvJuuiEpTK6x+vxPmvAj9TgV7A/z0Lrx0Nrw0HbZ9ALZeDAX1cVabnZX7/G/kQluGap2KpZmf8BM9Cm4uv/xy8vLy2LhxI99++63z9unTp/Of//zHbYsTQqMFJoU9KAcvchma6a+0D0etJNxvmMww5iq4eRn8ehmMvgqMwXBsI3xyM/xnBPzwT6gMvM7mH2w8SnltI8lRZr8sAXeVrc2YKpK8G+EfepxdmZKSwrhx48jPz3dOCJ80aRLDhg1z2+KE0KQ0NRIr6sXOjT8HN/1jwxnsCyXhvdH/VLj0RXXMw1l/B0sq1BTDikfgyZHw4a8gb21ATCa32uw898N+AG6bNhhTkP8lsrsaKjOmhJ/p0U+cw+HgoYceIjo6moyMDDIyMoiJieHhhx/GIfNnhAek9KJLcVEAHEtBc+t+vzmaak9kEpz5J7hrO1z+GgyYAg4b7PwEXp0JL5wBW96Cxp5Vx/mCDzYepaCinpSoUK6amK73cnptWNOMqb2FVSgBEHyKwNej4OZvf/sbzzzzDP/617/YsmULW7Zs4Z///CdPP/009957r7vXKIQzMOlJl+KiANi5AR8uCe+poGAYeSnc+A38diWMuw5MoVC4DT6dp/bMWXK/2kPHj7TYtTlrEKHB/t+5eWBCBCajgSqrjYJedAoXwlt6FNy8/vrrvPzyy9x6662MHj2a0aNHc9ttt/HSSy+xcOFCNy9RiJ7v3NQ32jnRlKOizcjxVxMH+nhJeG+kjoZLnoG7d8OMByF6ANQdh1VPwn/HwHvXwsEVfnFk9cGGI85dmysn+P+uDahDXLMSIwCpmBL+oUfBzfHjx9vMrRk2bBjHj0v7deF+PQ1uipu6GptNRqLDvDyXyc3UkvB4oLnrbcAJj4Of3QW/2wpXvwMDzwTFAXu+gDcuhuemwIZXoKFG75W2yWqz8+wPBwCYFyC7NhqpmBL+pEfBzZgxY3jmmWdOuv2ZZ55h9OjRvV6UEK319FjKdRq4weB/c31a06ZK+3S/G3cwBsGwC+CGz+C2dTDhJgiOgJLd8OXd8Phw+OavUHZA75W28P6GIxRW1pMaHcqVAZBr40pmTAl/0qOp4I8++igXXHABS5cudfa4WbNmDUeOHOGrr75y6wKFgOadm5oGO1X1jVhCu7YLU+jn3Ylb05KKN+eVU1HX6Pe7UV2SNAwufAJm3A9b34H1L8Lxg7D2WVj7HAw5R51MPuhsMOpXlVTfaOe5pl2b284ajNkUOLs2IDOmhH/p0f8EZ555Jnv37mXOnDmUl5dTXl7OpZdeys6dO3nzzTfdvUYhiDCbsJjVWLw75eCB0OPGVXpcOIMSI7A7FP63r1Tv5XhXaDScdivcvgmu/QgGnwMosO87ePsyeGYCrH0e6it0WV6LXZsJ/XVZgydpOzf7iqqxB0JCuwhoPf41Jy0tjX/84x98/PHHfPzxx/zf//0fJ06c4JVXXnHn+oRwSnE28uv6fBvXY6lAMa2vHE21x2hUd2t++RHcsRlOuw3MUXD8AHzzZ7XK6ss/QEmO15ZU32jnueVahVTg7dqAGliHBhux2hzkHa/VezmdkpL1vs2/O0uJPsUZ3HRj5ybQjqWguVvxir0l8h94/CA4b75aZXXB45A4DBqqYcPL8OwkeOMS2PMVOOweXcb7G45QVGklLUB3bUAdgzIkSZsQ7tvVenUNds5+fAW/eGmt3ksROpHgRvgNLUDpy8dSAJMGxhEWHERxIJaE95Q5Eib+Gm5bC9d/BsMuBIMRDi6H966Bp8bCqv9CrfurOfvCro1Gq5jKKfTtMQyb806QW1rD6gNl/jWuRLiNBDfCbzjLwbtRMdV8LOXfPW5cuZaE+323YnczGCDrTLj6bbhzK0z9HYTFqo0Al9ynHll9dgcU7nDbt3xvfZ7Lrk1gVUi1ps2Y8vWk4q1Hyp1/PlDq24GY8IxuVUtdeumlHX69vLy8N2sRokPJ3TyWUhTF2ecmyRI4OzegHk19v6eYFTklzDtrsN7L8U2xGXDOQzDtHtj+Eax/AQq3w+Y31MuA02Hyb9RdnqCeVZ2puzZNfW3OHkyIKbB/XxzqJ+XgW/JOOP98sKSG8QNidVyN0EO3gpvo6OhOv3799df3akFCtKe7OzcnahtpsKuzzgIp5wa0pOKdbMo70XdKwnsqOAzGXwfjfqkO5lz/Auz6DPJWqxdLGky8EcbPhcjEbj31u+vzKK6y0i8mjCtODexdG2ieMZVbWoPVZvfJIzhFUVru3JTIzk1f1K3g5rXXXvPUOoToVHe7FGtBUHxESMD9Rp0eF05WYgQHS2pYtb+U80el6r0k32cwQMYU9VKZDxtfg02vQVU+LPs/WPEojLhU3c3pd2qnT1ffaGeBtmtzVuDv2oA6wiQq1ERlvY2DJTUMT43Se0knOXqijtLqBuf1gxLc9EmB/9MoAkZyU95MabWVRnvn0+eLArBSytW0oX28JLw3otLg7L/B73fCnBfVYMbeANveg5fOhpemw7YPwNZ+24F31jXv2lx+amBWSLVmMBjI9vFmfluadm2CjGpH8oMlvjmqQ3iWBDfCbyREmDEZDSgKlFR13usmEHvcuJKScDcwmWHMVXDzMvj1Mhh9NQSFwLGN8MnN8J+RsOwfUFnQ4mH1jXYWrFB3bW7vA7k2rporpnw0uGnKt9G6eR8uq5Wmg31Q3/mJFH7PaDSQZFF3b7pyNKUdSwXqzo1WEl5UaWV3gW9+0PiV/qfCpS/A73fBWX8HSyrUFMOPj8KTI+HDX6k5O4rC2+vyKGnatblsfN/YtdH4+s6Nlm9z/qhUzCYjDXYHR0/4ftNB4V4S3Ai/0p0BmtqxVCD1uHEVGhzEFK0kfK8cTblNZCKc+Se4aztcsVCtqnLYYOcn8OpMHM//nGM/vIiZhj63awO+XTFltdnZeUzt/XRqRiwDEyIASSpu7aHPd3Huf1bw/z76iQ83HiGvrDbgdn97NDhTCL10J6k4EHvctHZWdiLL9hSzPKeE26ZJSbhbBQXDiDnqpWCbOrBz+4cYi7ZzH9u5M/RNLOU3QvmvIWaA3qv1Gi24OXK8jhqrjQiz73yM7C6oosHuIDY8mIz4cAYlRrKnsIqDJTWcPUzv1fmGoydqeXVVLgB7i6r5YONRQE0WnzQwnkmZsUwaGM+QpEiMTXlL/sh3/lUK0QXJ3QluAvxYClxKwg+foLK+kaguTkv3dQ02Byv3lfD5T/lsOHSC300fwpUTdSy1Th0NlzxD3bQHePG/D3CZ/Wv6G0ph9X9hzdOQfT5M+g0MPEOtygpgcREhJFrMlFRZ2Vdczdj0GL2X5KTl24xNj8FgMJCVqO3cSFKx5tOt+QCM7BfFz4cksj73ONuOllNUaeXzn/L5/Cf169FhwUzMjGXSwDgmZsYxsl80wUH+s0upa3Dz448/8thjj7Fp0yYKCgpYtGgRs2fP7vAxzz77LM888wyHDh1iwIAB/O1vf5PeOn1ISjeOpYqbko4DObhpURK+r5RZflwSbncorD1Yxuc/5fP1jkIq6prb5v/5k22Yg41cMrafjiuEt7dV8p/aWXwccwnLLrZi2viSOuJhzxfqJXE4TLoZRl+ljoQIUNnJFkqqrOwtrPKp4EbLtxmbrjbt04IbKQdXKYrCp1uPAXDdaRlcNVHdcaxvtLMlr5wNh46zPvc4m5v6Zy3dXczS3eqRd1hwEOMzYpiYGcekgXGMS48lLMT3+hxpdA1uampqGDNmDDfeeGOn3Y8BFixYwD333MNLL73ExIkTWb9+PTfffDOxsbFcdNFFXlix0FtXj6WsNjvHaxpaPCZQTRuaxMGSXJbnlPhdcKMoCpvzTvD5TwV8sa2A0urmKrgki5kLRqdSVW/jo01HufuDn4gIMTHjlGRd1lrXYOf5FQcBmDc9G9MpA+CUC9Xp4+tfhK3vQslu+PJuWPogjLtWnXcVP0iX9XrS0GQL/9tfyh4fq5jaklcOwLgBMQAMSlQDzIOlsnMD6rHd3qJqQoKMnDey+f8KLX9Py+FrtDvYmV/JhtzjrMs9zsbDxymvbWTV/jJW7S8DIDjIwKh+0UwcGMfkgXGcmhHnU81EdQ1uZs2axaxZs7p8/zfffJPf/va3XHXVVQBkZWWxYcMGHnnkkXaDG6vVitXa/B9mZaUMGvRnzcMzOy4F18YuhJiMxIT7zg+cJ0zLTuTVVbnOknCDjx+LKIrCroJKPvspny9+KuBYeZ3zazHhwcwamcpFY1KZPDCeIKMBh0PB7lBYtOUYt72zmYVzJ3L64ASvr/vtdYcprbaSHhfGpa4VUonZ6kTy6ffB1ndg/Utw/ACsfQ7WLoCM02HAFEifBP0nQnic19fubr44Y6qs2krecbUqakzTbpKWUFxSZQ2oY9ue0nZtzh6W1GEgEhxkZGx6DGPTY7j5jCwcDoX9JdWsyz3Ohlx1d6ewsp7NeeVszivnhRUHMRjUHb3JA+OYODCOSZlxJOn4i6Vf5dxYrVZCQ1v+ZYWFhbF+/XoaGxsJDj75zZo/fz4PPvigt5YoPEw7liqsqO/wg7zQpVLK1z/se0srCS+srGdPYZVPdo0FtWLls635fL4tv0VjtYiQIGaOSOGiMWlMHZxwUvWR0WjgsctHU221sWRXEb9+YyNv/3oy47w4L0jdtVH72txx1pC2cw9Co+G0W2HSb+HAMnXMw77v4PAq9aJJGKoGOumTof8k9brRf3IZwDcrprQjqUGJEc4PbktoMEkWM8VVVg6W1PjUEZq3ORyKM99m9ri0bj3WaDQwNNnC0GQL152WgaIoHD1R1xzsHDpObmkNewqr2FNYxetrDhMSZGTbA+cSGqzP0ZVfBTczZ87k5ZdfZvbs2YwfP55Nmzbx8ssv09jYSGlpKampJ2/J33PPPdx9993O65WVlaSnB/4MmEClHTHVNdqprLe1+9uHlkwc6EdS0LylrFVN+VJwc/RELV9sK+CzrfnsKmjeNTWbjEwfnsRFo9M4a1hSp/8BmoKMPH3NOG56fQOr9pcx97UNvP/b05yzjjztrbWHKa1uYEBcOHPGd5L3YzTCkBnq5Xgu5K6AIxvgyDoo2wele9XLlrfU+4dGq0FO+mRIn6h2SzZbPP+iekELbkqqrByvaSAuIkTnFZ2cb6PJSoxoCm58K/nZ29bmllFYWY8l1NRUiNBzBoOB9Lhw0uPCnd25i6vq2ZB7wpm3E2k26RbYgJ8FN/feey+FhYWcdtppKIpCcnIyN9xwA48++ijGdn7zMZvNmM2BWwrc14SFBBEdFkxFXSNFlfXtBjfO0QsB2p24tWnOkvBibp2mb45HcVU9X20r4PNtBWw63Dyd2WQ08PMhCVw8No0Zw5OxdPOIIDQ4iBevm8AvX1nHlrxyfvnyej66ZQqZTUcPnlLbYOOFH5u7EXerYiRuoHo5da56vaYMjm6Ao+vhyHo4tgnqK2D/EvUCYDBC8ojmnZ30SRCb6VNVWBFmE+lxYRw5XsfeoipOy4rXe0nO4EbLt9FkJUay9uDxPj+G4dMt6q7NBaNSPRJ0JFlCuWB0KheMVjcZbF0YkeNJfhXchIWF8eqrr/LCCy9QVFREamoqL774IhaLhcTE7k3zFf4rJSqUirpGCivqnb9Btta8c9M3Alt1zpR+JeHltQ18s6OQz7fls+ZAGVq3e4MBThsYz0Vj0pg1MoXYXv6GH2E2sXDuJK56cQ17Cqu49uV1fHjLFNJiwtzwKtrWYtdmXC+rtSLiIfs89QJgb4SiHWqgo10q8qBwu3rZ8HLT45KajrKadnhSx0KwvoF7drLFZ4Ibh0Nha1Mycevdmeak4r5bMVXfaOerHeoIEW9VHJp0Lhv3q+BGExwcTP/+6lbYe++9x4UXXtjuzo0IPMnRoeQUVXVYMVUY4EMzWxsQH05WQgQHS71bEl5cVc/9n+5k6e4iGu3NHU7HDYjhotFpXDA61e3vQXR4MG/eNJkrX1hDbmkNv3xlHR/8dgoJke4PZGsbbLzQVCHV7V2brggKhrRx6mXyb9XbKvObA52j6yF/qzoGQis3BzAGQ9rY5p2d9MkQ5d1KuaHJFpbuLvaJGVMHS6upstoIDTYyLKXlLzzOXjfFfXfnZnlOMVX1NlKjQ5k80P8T2rtC1+Cmurqa/fv3O6/n5uaydetW4uLiGDBgAPfccw/Hjh3jjTfeAGDv3r2sX7+eyZMnc+LECZ544gl27NjB66+/rtdLEDrQdmM66nVTFOBDM9tyZnYiB0trvFYSvuNYBb95YyP5Te/DsBQLF49N46LRaaTHhXv0eydazLz168lcsWA1B0tquP6V9bz7m9PcXor61trDlNU0kBEfzqW93bXpqqg0GDFbvQA01kPBVjVnRwt6aoqbjrc2wNpn1ftFD1BzdtInqwFP8kg1ePIQX5oxtblp12Z0v5iTdgwGJag7N7llNdgdinNaeF+yuOlI6uIxaX7ddbg7dA1uNm7cyFlnneW8riX+3nDDDSxcuJCCggLy8vKcX7fb7Tz++OPk5OQQHBzMWWedxerVq8nMzPT20oWOtCThAtm5aWFadhKvrTrklZLwr7cXcPcHP1HXaCcrMYKnrxnHiLRoj32/tvSLCeOtX6s7OLsKKrlp4QbeuGkS4SHu+W+txa7NWYP122YPDoUBp6kXAEWBE4ead3aOrIOinepxVkUe7Pi46XHhanJyf5eAx41l6K7TwfVuQdBevg1Av9gwQkxGGmwO8svrPB54+5qKukaW7VEb8endBNObdA1upk2b1uGwroULF7a4Pnz4cLZs2eLhVQlf19nwTEVRnH1w+kK1lGbywDhCg40eLQlXFIWnvt/Pf5buBeCMoYk8fc043Zp3ZSVG8saNk7n6xTVsPHyC3765iZdvmIDZ1PuEyTfXNO/a9DrXxp0MhuZE5TFqzy+sVWpyslaVdXS9mqh8aKV60cQPaZm7k5Dd4zL0rMQIgowGKuttFFVadd0l3dJOvg1AkNFAZnw4e4uqOVBS3eeCm292FNBgdzA0OZLhqb5dhedOfplzI/q2zroUl9c20mBTM/WT+khCMTSVhGfF80NOiUdKwusa7Pzxo5/4cpuamHjj1IH89fxhuicOnpIWxWu/msQvX17Hyn2l/O7drTzzi3G9WpdaIaXu2txx9hDdX2OnzBbImqZeABwOtdxcC3SOrFevl+1TL1vfbnpcNPSf0Lyz0+9UCO3avxuzKYiBCRHsL64mp6hKt+CmtsFGTqHaZqC93keDEiPZW1TNwZIapmV7c3X6046kLhnbL+B7frmS4Eb4neYuxW0HN1rQExcR4pbf4P3JtOykpuDGvSXhhRX13PzGRrYfqyA4yMDDl4zk6km+Mwn71IxYXrp+Ajcu3MA3Owv588fbeezy0T3OL3hjzWGO1zSQGR/O7LHda3jmE4xGSBqmXk69Qb2t9riao3Ok6Sjr2CawVsCB79ULqGXoSac07+ykT4LYge2WoWcnW9hfXM3ewirOHKpPxeq2oxU4FPWXnvYCrOYBmn2rYqqgoo61ueq4hEv88d9xL0hwI/yO9h9YaXUDDTbHSR1t+2K+jWZatvoBs+nwCarqG7vdS6YtW/JO8Js3N1FSZSUuIoQF145nsg/0NWntZ0MSePoX47jt7c18vPkollAT9190Srd/W62x2njRn3Ztuio8DobOVC8Adptahn606SjryDooz1NvK9oBG19V7xeR2LIqK20sBKul90OTLXy5vUDXTsUd5dtospqSivtar5vPtuajKDApM47+sX3rOE6CG+F34sJDCA4y0GhXKK6qP+mHtqiP9bhxlREfwcCECHJLa1i1v7TFcLyeWLzlGP/v42002BxkJ1t4+YYJPp2zMHNECo9dPpq7P/iJhasPERVq4u5zu3cOoe3aDEyICOzfdoNMaqCSNladZA5QVdi8s3NkvVqlVVMCOV+qF1DL0FNHQ/pkzmAo72Bib5F3k8ldbclTG0V21H3YOR28j/W6Wdw0buGSbo5bCAQS3Ai/YzQaSLKEcqy8jqLKk4Obwj5YBu7qzKGJ5DaVhPc0uHE4FP79XQ7PLVc7884YnsyTV48l0uz7/2VcOr4/NVYb9366k6eW7ccSGszNZ2R16bHqrk3TDKmzdayQ0oslBU65WL1AUxn6T81VWUfWQ3WReqR1bBPjgHWhkF8Sj+PDMzFqR1kpozxahq5RFKXDZGJNVlMjv6JKK9VWm1/8O+6tvUVV7C6oJDjIwAVe6nvlSwL/HRYBKSVaDW4KK06eDl7Uh4+lQD2aWrj6EMtzelYSXm218fv3t7JkVxEAt04bxJ/Ozfar/hjXTcmkst7GY9/m8I+vdhMZauKaLuQIvbHmMCdqGxmYEMHFY/reb7snCQ6FAZPVC3eoZejlh51VWcqRdTgKtpNmKIOdn6gXAFMY9BvfckBohPuPMgsq6imushJkNDCqf/u7R9FhwSREmimttpJbUtPhfQPF4i3qBPAzhyYRE67/7C9vk+BG+KWOKqb60tDMtpyWFY/ZpJaE5xRVdWu45JHjtdz8xkb2FFYRYjLyyGWjmDOuvwdX6znzzhpMVb2N51cc4K+LthNhNnUYsFT39V2brjAY1DlXsZkw+goMwFVPfUdw4VYeGl/DEOsudXenvvzkaehxg5qTlNMnQ+KwXk9D1/JtspMtnfY3ykqMoLTayoGS6oAPbnozATxQSHAj/FJHFVOFTT1u+srQzNa0KeHLm0rCuxrcrM89zi1vbeJ4TQMJkWZevP5UxrdTWusv/nxeNlX1jby9Lo+7399KpDmIs4clt3nfN9Yc4kRtI1mya9MtA1KS+CR/BN/EDmXI9CFqGXrZ/uYk5SProTQHjh9QLz+9oz7QHNWqDH1Cl8vQNVq+TUfJxJpBiRGszz3OwT5QMbUp7wTHyuuINJuYMbztf++BToIb4ZdSotVk4cI2GvkVa8dSlr4Z3ABMG5rYFNwUc8uZnZeEv78hj78v3kGjXWFEWhQvXT/Bo8MovcVgUMvWq602Pt2az61vbeb1GyedNOix2rVCarrs2nRHttapWKuYMhohcah6GX+delvt8aYmg00Bz9FNYK2EA8vUCwCGk8vQ47I6nIau7dx0lG+j0SqmDpQGfsWUdiQ1c0SKRyaA+wMJboRfSm7nWMpqs1NW0wD03YRiUPvd8PkuNh7quCTcZncw/+s9vPK/XADOH5XCv68Y47YRBr7AaDTw7yvGUGO1s3R3ETct3MA7N5/GGJcPxNdXH6LcuWvjQ92I/cDQrsyYCo+DIeeoF1DL0It3uczLWqfm8hTvVC+bXmt6XHxzoNN/kjpgNEQtIGi0O9h2tAJov3mfK2fFVICXgzfYHHy5XW202VePpECCG+GnUto5lipuOpIKMRmJDddnJIAvyEyIIDM+nENltazaX8Z5I1NOuk9FXSN3vLuFH/eWAHDXjCHcefYQv0oc7qrgICPP/GIcNy7cwOoDZdzw2nre/80UslMsVFttvLRS3bW5c/qQPjlYsTe0nZuDJTVt9p1qU5BJLSdPHe1Shl7UsiorfwvUlkHOV+oFwGiCFLUMvSBiJHE2B9WhyWQlRHT6LQc1VUzlllbjcCgB+e8cYMXeEsprG0m0mDl9UILey9GNBDfCL2m7MoUV9S0qgporpcx9qtV4W6ZlJ7Fw9SFW7C0+KbjJLa3hptc3cLCkhtBgI09cOZbzA7xcNDQ4iJeun8C1L69j65FyfvnKOj66ZQpfbCtQd20SI7hIcm26LTU6FIvZRJXVRm5pjXNaeLdZkmH4ReoFwGaFgm0tc3eqCyF/M+RvZgCwJhTKghIwfvzz5qqslFFgOrk6qH9sGMFBBuobHeRX1AVsU7vFW9UjqYvHpPXpQF2CG+GXtGMpq81BRV2js9TR2eOmj1ZKuTqznZLw/+0rZd47m6moayQ1OpSXrp/AyH6BXT2iiTCbWPiriVz94lr2FFZx7cvrqLbaAPid7Nr0iMFgYGiKhU2HT5BTVNXz4KY1kxnSJ6oXblfL0CuOOI+xjmxbTmrdfuLtpbBzkXoBMIVCWlMZer/xkDwSYgdiCjKSEa/OwjpYUhOQwU1VfSNLm1o4zO5DE8DbIsGN8EuhwUHEhgdzoraRwsr65uCmom/3uHE1pakkvKCinr1F1WSnWHhjzSEe/HwXdofC2PQYXrzuVJL62N9VTHgIb9w0iSufX8OhslpAraS5cLTs2vTU0GQ1uNlbWAVjPPRNDAaIGaBeRl3ODbuWU2At451ZIYwz5KhBz9H1UHcC8larF01wBCSfwr1KMkuCEqneZ4UBM7pdneXrvt1ZhNXmICsxgpH9Auu1dZcEN8JvJUeFqsFNRb2z3LlIdm6cQoODOC0rnhV7S1i6u4g31hzi7XV5AMwZ14/5l47qs5UUSZZQ3vr1ZK54fg0FFfXcNWOo7Nr0Qnayms/irRlTFbWNHCytAULJmHAORDQdZSlKyzL0gm1QvBsaa+DoBs4EzgwGNrwGG4CYDPUYK3mEusOTMhJiMnvdf0cvnzYdSc3uYxPA2yLBjfBbKdGh7CmsapFUrPW46cuVUq6mZSeyYm8Jj3+Xg0NRf/n9fzOHccuZWX3+P7/+seF8dvvP2FNYyc+H6DPROlB0qWLKjbYeLQcgMz6cuAiX/BqDARKGqJdxv1Rvs9vU/jqF29m9dTUFezcxNuQocfZStUKr/DDs+aL5OUIi1ZL05BFqsJM8CpJPAbObjts8pLiqnlX7S4G+NwG8LRLcCL+l7c4UuPS6KZJjqRamZSfx4Oe7cCgQERLEk1eP45xT+mZTr7YkWswkWiSw6S2tYirveC21DTaPtxLoyrBMpyATJGZDYja1UdO5cedqUsNDWfOHcer088IdULQTirZD8R5oqFaPt46ub/k8sZnq7o62w5M8wqd2eT7/qQCHojY0zIjvvHos0ElwI/xWW12KC/v4XKnWBiZEcO4pyRwuq+W/14zt1igGIboqPtJMQmQIpdUN7CuqbtFDyBO05n1d6W/jalBTr5uCinpqTVGEDzwDBp7RfAe7TT3WKtrhEvjsgKoCOHFIvbTe5Uke0XyslTxSt10e1yMpIcGN8GOu5eCgTgiWnJuTvXj9BL2XIPqA7BQLpfvLyCmq8mhwoyhKtzoTu4oJDyEuIoTjNQ0cLKk5uUowyARJw9TLqMubb68paw54inZC4XYoadrl0fJ7XMUObDrWGtUU8IxQ83s8tMtzoKSabUcrCDIauHB0YLd06CoJboTfah6eqebZVNQ1YrU5AEiKMuu2LiH6oqHJFlbtL1MrpjzoUFkt5bWNhJiMDE/t/k7koMQINbgpbSO4aU9EPGSdqV409kZ1l0fb3dECn6oCOJGrXlrs8ljUXR3nsdZINbfHHNnt19Dap03jFs4YkkB8pPzfBxLcCD/W+lhKO5KKDQ/us1VAQujlpBlTHqLl24xMi+paN+RWshIi2XDoBAeKezlAMygYkoarF65ovr2m1GWHpynoKdkDDVVt7PIYIK5plyd5VHMSc0xGhzO1XCmKwmLnBHA5ktJIcCP8lnYsdbymAavNLj1uhNCRtyqmeppvo3HOmPLUAM2IBMiapl409kYo3decuKwlMVcXwvGD6mX35833D7G4VGuNaK7YCjk5UXjLkXLyjtcSHhIkxQIuJLgRfis2PJgQk5EGm4PiSmtzvo2UgQvhdUOS1OOVokor5bUNzsaa7rYlrxzofr6NJqtpxtTBkl7u3HRHUHDTkdQptLnL43q0VZLTtMuzVr04abs8I1scbX26uRKAc09JDqiBt70lfxPCbxkMBpKjzBw5XkdhZT2FFU09bmTnRgivs4QG0y8mjGPldewtqmbSwDi3f4/6Rju7C9QP83EDYnr0HNrOTW5pTYuxJLpod5dnb3PictFONeipLnLZ5fnMefc/Ec4FIemk2SfCxglqEnPS8DZ3efoSCW6EX0uJClWDm4p6KQMXQmfZKRaOldeRU1TlkeBmx7EKbA6FhEgz/WLCevQcA+LCMRkN1DbYKaysJzW6Z8/jMUHBzeXlo69svr26pFXF1g4cJXuIdNQyyZgD+3Jg31tNdzZAXFZz4rKzYmtAl3N5/J0EN8KvuSYVy7GUEPoammxh2Z5ij1VMNefbxPR4xyU4yMiA+HAOltRwoLjG94Kb9kQmQuRZMOgs501/enc9O7Zt4jdDa7ms34nmJOaaYrUr8/EDsOvT5ucwRzcHTs6KrcDc5ZHgRvg1Zzl4Rb1LQrGUQgqhh+wUz86Y6m2+jSYrIZKDJTUcLK3mZ0MSer8wHdRYbXy16zh1ygAGTj8dXBOsq4tbdV9uyuWxVpw8VBQDxA9qTlzWkpij0/16l0eCG+HXnI38KusprpJjKSH0NDS5uWLKE/kszp2bXgY3gxIjWLobDpZ4qGLKC5bsKqKu0U5GfPjJfx+RSRB5Ngw6u/k2W0NTLk+r7ss1JWq/nrL9be/yuB5tJQ2HkHCvvL7ekuBG+DUtkDl6oo7S6gZAEoqF0MugxEiMBiivbaSkykqSG38WiyvrOVZeh8EAo3u7c9OUVHzAmxVTbra4adzCJV2dAG4KUQOVlJEtb68ubkpcdunNU9rOLo/BCHGDTg56ovv73C6PBDfCr2k7N7uaKihCgowtpwQLIbwmNDiIzIQIDpbUkFNU5dbgZkvTrs3QJAuR5t59dA1yloP7585NabWVlfvUCeCzezsBPDIJBk9XLxpbgxrguJaoF+6A2lIo26dedi1uvn9o9MlDRZNOgWD98pkkuBF+TdulaXAZu6BraacQfdywFIsa3BRW8fMh7pu4ruXb9LQE3JXW6+ZYeR11DXbCQvyro/mX2wqwOxRG9492vha3MoWoJeUpo1reXlWkNiF0dl/eqQZB9RVweJV6cT5HKNxzTJ3XpQMJboRfaz1DSo6khNDX0GQLX20vJMfNFVNbj6hjF3qbTAwQFxFCTHgw5bWN5JbWcEpa92dU6cn1SMqrLMnqZfCM5ttsVjVZWUtc1o64LGm6BTYgwY3wc2ZTEPERIZTVqPk2yVIGLoSuspPdP4bB7lDYdrQC6PnYhdayEiLYnFfOwdJqvwpuDpfVsCWvHKMBLhrjAxPATWZIHa1eNIqiTkzXkWfmrwvhRa7VUbJzI4S+mmdMVeNwKG55zr1FVdQ22IkICWJwknuOYbL8NO/m06YhmVMHJ5Bk8dH/7wwGMFt0XYIEN8LvuTbtk+BGCH1lxIUTYjJS12jn6Ik6tzynVgI+Jj2GIKN7cuoG6TFjqpfUCeA6HUn5GQluhN9z3blpnYMjhPAuU5CRwYnubea3Jc99+Taa5nJw/9m52X6sgoMlNYQGG5k5QiaAd0SCG+H3UuRYSgifkp3i3ryb5rEL7sm3AbWRH6g7N4rinuMzT1u8RT2SmjE8GUtosM6r8W0S3Ai/lxJtdvmzBDdC6E3rVOyOiqmq+kb2FatHR+7cuRkQF0GQ0UBNg53iKqvbntdT7A6Fz7epwc1sOZLqlAQ3wu+5HkvJ6AUh9KfNmHLHzs22oxUoCvSPDSPR4r5j5xCTkfRYtcmcP3QqXn2glJIqKzHhwZwx1H39gwKVBDfC72XEq9vLSRYzocH+1YxLiECk7dwcKKmm0e7o1XN5It9G40+dirUjqQtGpRJiko/uzsjfkPB7AxMieOzy0Tx9zTi9lyKEAPrFhBEREkSjXeFQae8CB0/k22j8ZcZUfaOdb3cWAjB7nBxJdYUENyIgXDEhnclZ8XovQwgBGAwGZ7+b3lRMKYriHLvgiZ0bf+l1s3R3EdVWG/1iwjjVA0FeIJLgRgghhNsN0yqmepFUfPREHWU1DQQHGRjhgS7CWQlNFVOlvr1zox1JXTI2DaOb+vwEOgluhBBCuJ2zYqoXOzebm/JtTkmN8kg+nbZzc/REHfWNdrc/vzucqGlgeU4xAHPkSKrLJLgRQgjhdtluKAf3ZL4NQEJkCFGhJhQFDpX55tHUl9sLsDkUTkmNYkiyviMN/IkEN0IIIdxOy7k5fLyWuoae7Yp4Mt8G1NwgX8+7+bRp3MLscWk6r8S/SHAjhBDC7RIizcRHhKAosL+4+zktVpudXfmVAIwbEOPm1TXLculU7GuOnqhlw6ETGAxw8Rg5kuoOXYObH3/8kYsuuoi0tDQMBgOLFy/u9DFvv/02Y8aMITw8nNTUVG688UbKyso8v1ghhBDd0pu8m135lTTYHcRFhDAgLtzdS3Py5V432gTw0wbGS/f1btI1uKmpqWHMmDE8++yzXbr/qlWruP7667npppvYuXMnH374IevXr+fmm2/28EqFEEJ0V29mTDkngfePxmDwXIWQVjF1oJf9eNxNURQ5kuoFk57ffNasWcyaNavL91+zZg2ZmZnceeedAAwcOJDf/va3PPLII+0+xmq1YrU2zw2prKzs+YKFEEJ0WW9mTGn5Np5KJtYMSmrauSlWB2h6MpDqjt0FVewtqiYkyMh5I1P1Xo7f8aucmylTpnDkyBG++uorFEWhqKiIjz76iPPPP7/dx8yfP5/o6GjnJT093YsrFkKIvqs3M6a0nRtPJRNrMuLDMRqgymqjpNp3BmhquzZnD0siOkwmgHeXXwU3U6dO5e233+aqq64iJCSElJQUoqOjOzzWuueee6ioqHBejhw54sUVCyFE36WVLhdU1FNR19jlx5VVW8k7XgvAGA8HN2ZTEP1j1ZweX8m7cTgUZ76NjFvoGb8Kbnbt2sXvfvc77rvvPjZt2sQ333zDoUOHuOWWW9p9jNlsJioqqsVFCCGE50WFBpPWlAi7rxu7N9quzaDECK/sWjRXTPlGcLM2t4zCynqiQk2cNUwmgPeEXwU38+fPZ+rUqfzpT39i9OjRzJw5k+eee45XX32VgoICvZcnhBCilZ7MmPJWvo0mK0GrmPKNcvDPf1J3bc4flYrZ5P7OzH2BXwU3tbW1GI0tlxwUpL7xiqLosSQhhBAdyO7BjClv5dtoBiX5znRwh0Nh6W513ML5oySRuKd0DW6qq6vZunUrW7duBSA3N5etW7eSl5cHqPky119/vfP+F110EZ988gkLFizg4MGDrFq1ijvvvJNJkyaRlialckII4Wuyu9nrxuFQ+Mk5diHGQ6tqyblz4wPl4NuPVVBSZSUiJIjJWXF6L8dv6VoKvnHjRs466yzn9bvvvhuAG264gYULF1JQUOAMdADmzp1LVVUVzzzzDH/4wx+IiYnh7LPP7rAUXAghhH5cy8G7Ump9oKSaKquNsOAgZ2DkaYOacm6OHK/FarPrehT0/e4iAM4YmihHUr2ga3Azbdq0Do+TFi5ceNJtd9xxB3fccYcHVyWEEMJdBidFYjTAidpGSqqtJFk67rS7pWnXZlT/aExB3jlcSLSYiTSbqLbayCur1XVApXYkNX14sm5rCAR+lXMjhBDCv4QGB5EZr+6M7C3sPKfFmUzspXwb0AZoank3+h1NFVTUsaugEoMBzsqWKqnekOBGCCGER3VnxtRWL+fbaLQZU3omFX/ftGszfkAs8ZFm3dYRCCS4EUII4VFDu1gxVWO1kVOojsgZm+6dMnCNNmNKz143Wr7N2cOSdFtDoJDgRgghhEd1tWJq+7EKHAqkRod6fQp2ljYdvFSfnZvaBhurDpQBMEPybXpNghshhBAepc2Y2ldUhcPRfhGJlm/jrf42rly7FOvRN23V/jIabA76x4YxNDnS698/0EhwI4QQwqMy4iMICTJS02DnWHldu/fbeuQE4P18G4CBCREYDFBR18jxmgavf3/tSGrG8GSfmUzuzyS4EUII4VHBQUbnzkh7E8IVRXHZufFuvg2oVV39YsIA71dMORwK3+9Rk4kl38Y9JLgRQgjhcdmdzJgqqKinuMpKkNHAqH7R3lyakzPvxssVU9KV2P0kuBFCCOFxnc2Y0nZthqVYCAvRpzOvs2LKy2MYpCux+0lwI4QQwuOaK6ba3hXRM99GM8iZVOzdnRvtSEq6EruPBDdCCCE8Tmvkd6C4GpvdcdLX9cy30TQfS3lv56agoo6d+dKV2N0kuBFCCOFx/WLCiAgJosHu4FBZbYuvNdodbD9WAehTBq7RuhQfPl5Lg+3kAMwTtK7E49JjpCuxG0lwI4QQwuOMRoNzIGVOq7ybPQVVWG0OokJNzrwXPSRHmYkICcLuUMg7Xtv5A9xAy7eRIyn3kuBGCCGEV7TXqVjLtxmTHoPRqF+PF4PBwEAv5t1IV2LPkeBGCCGEV7Q3Y8o5CXyAfvk2mqwEbQyD5/NupCux50hwI4QQwiu0nZvWjfyck8B1zLfRaM0GDxR7fufGeSQ1LEm6EruZBDdCCCG8YmjTjKlDZTXUN9oBKK9tcO6S6JlMrBmU6J2dG9euxJJv434S3AghhPCKxEgzseHBOBTY37Qzou3aZMaHExsRouPqVFleyrmRrsSeJcGNEEIIrzAYDM5+N9rRlPNIygfybUAdoAlworaREx4coKnt2khXYs+Q4EYIIYTXtJ4x1dy8L0anFbUUHmIiLToUgIOlntu9kRJwz5LgRgghhNe4zphSFMVl5yZGv0W1onUqPlDsmbwb167E06QrsUdIcCOEEMJrmiumqsktraGirpEQk5FhKVE6r6yZNmPqgId2bly7EidIV2KPkOBGCCGE12hdio+V1/G//aUAjOoXTYjJdz6OPD1jSo6kPM93/jUJIYQIeNFhwaQ25bS8v+EI4Dv5NhpPVkxJV2LvkOBGCCGEV2kVUzvzKwHfyreB5p2bvOO1NLYxwbw3pCuxd0hwI4QQwqu0pGKNr+3cpEaFEhpspNGucMTNAzSlK7F3SHAjhBDCq7SdG4BEi5l+MWE6ruZkRqOhecaUG/NupCux90hwI4QQwquyXYKbsekxPrmD4cy7cWPFlHQl9h4JboQQQnjV4KRItHjG1/JtNJ6omJKuxN4jwY0QQgivCgsJcu7eTB7omzsYg5wVU24Mbprybc4eluS25xRtM+m9ACGEEH3PU9eM42BJNadm+Gpw09Sl2E3l4K5dic+S4MbjJLgRQgjhdUOTLS0Si32NNkCzrKaBitpGosODe/V80pXYu+RYSgghhGglwmwiJUptNuiOMQzLpErKqyS4EUIIIdqQ5aa8m7oGO6uaRk1IV2LvkOBGCCGEaIO7xjD8b38pVpuDfjHSldhbJLgRQggh2uCupGKtSmrGcOlK7C0S3AghhBBtcEevG+lKrA8JboQQQog2ZDVVTB0uq8XuUHr0HDvypSuxHiS4EUIIIdrQLyYMs8lIg93B0RM9G6C5tKkE/OdDpCuxN0lwI4QQQrTBaDQ4+9309GjKOQV8uDTu8yYJboQQQoh29CapWLoS60eCGyGEEKIdWjn4gR7s3EhXYv1IcCOEEEK0oze9bqQrsX4kuBFCCCHakZXQVA5e2r2dG9euxJJv430S3AghhBDt0HZuSqqsVNY3dvlxrl2Js314QGigkuBGCCGEaIclNJgki5ov052KKelKrC8JboQQQogOdDfvxuFQJN9GZ7oGNz/++CMXXXQRaWlpGAwGFi9e3OH9586di8FgOOkyYsQI7yxYCCFEn9PdMQw78isolq7EutI1uKmpqWHMmDE8++yzXbr/f//7XwoKCpyXI0eOEBcXxxVXXOHhlQohhOirtDEMB0u7tnMjXYn1Z9Lzm8+aNYtZs2Z1+f7R0dFER0c7ry9evJgTJ07wq1/9yhPLE0IIIZob+RV3bedGuhLrT9fgprdeeeUVZsyYQUZGRrv3sVqtWK1W5/XKykpvLE0IIUSA0IKb3LIa7A6FIGP7CcLSldg3+G1CcX5+Pl9//TW//vWvO7zf/PnznTs+0dHRpKene2mFQgghAkG/2DBCTEYabA7yy+s6vK+WSCxdifXlt8HN66+/TkxMDLNnz+7wfvfccw8VFRXOy5EjR7yzQCGEEAEhyGggMz4c6HzGlDZyQaqk9OWXwY2iKLz66qtcd911hISEdHhfs9lMVFRUi4sQQgjRHc5OxR1UTElXYt/hl8HNihUr2L9/PzfddJPeSxFCCNEHNA/QbH/nRroS+w5dE4qrq6vZv3+/83pubi5bt24lLi6OAQMGcM8993Ds2DHeeOONFo975ZVXmDx5MiNHjvT2koUQQvRBg7rQ60a6EvsOXYObjRs3ctZZZzmv33333QDccMMNLFy4kIKCAvLy8lo8pqKigo8//pj//ve/Xl2rEEKIvsvZpbidXjfSldi36BrcTJs2DUVR2v36woULT7otOjqa2tpaD65KCCGEaEnrUlxUaaXaaiPS3PLjU7oS+xa/zLkRQgghvCk6LJiESLWAJbeNoynpSuxbJLgRQgghukCrmGorqVi6EvsWCW6EEEKILhiU1PZ08MKKeulK7GMkuBFCCCG6wLlzU9ryWOr7PequzVjpSuwzJLgRQgghusBZMdUq50brSjxDqqR8hgQ3QgghRBdoFVO5pdU4HGqlr3Ql9k0S3AghhBBdkB4bRnCQgfpGB/kV6gBN6UrsmyS4EUIIIbrAFGQkI77l0dSyPdKV2BdJcCOEEEJ0UVZCc8WUw6E4823OlnwbnyLBjRBCCNFFWt7NwdKaFl2JT5OuxD5FghshhBCii1wrpqQrse/SdbaUEEII4U8GNQU3B0qqOVHbAEiVlC+S4EYIIYToIq2RX0FFPQUV9dKV2EfJsZQQQgjRRbERIcRFhDivS1di3yTBjRBCCNENWsUUSFdiXyXBjRBCCNENWlIxSL6Nr5LgRgghhOgGrRxcuhL7LgluhBBCiG64YFQqgxIjuOPswdKV2EdJtZQQQgjRDelx4Xz/h2l6L0N0QHZuhBBCCBFQJLgRQgghRECR4EYIIYQQAUWCGyGEEEIEFAluhBBCCBFQJLgRQgghRECR4EYIIYQQAUWCGyGEEEIEFAluhBBCCBFQJLgRQgghRECR4EYIIYQQAUWCGyGEEEIEFAluhBBCCBFQJLgRQgghREAx6b0Ab1MUBYDKykqdVyKEEEKIrtI+t7XP8Y70ueCmqqoKgPT0dJ1XIoQQQojuqqqqIjo6usP7GJSuhEABxOFwkJ+fj8ViwWAw6L0cj6qsrCQ9PZ0jR44QFRWl93I8Sl5r4OpLr1dea+DqS6/XU69VURSqqqpIS0vDaOw4q6bP7dwYjUb69++v9zK8KioqKuB/mDTyWgNXX3q98loDV196vZ54rZ3t2GgkoVgIIYQQAUWCGyGEEEIEFAluApjZbOb+++/HbDbrvRSPk9cauPrS65XXGrj60uv1hdfa5xKKhRBCCBHYZOdGCCGEEAFFghshhBBCBBQJboQQQggRUCS4EUIIIURAkeDGT82fP5+JEydisVhISkpi9uzZ5OTkdPiYhQsXYjAYWlxCQ0O9tOKee+CBB05a97Bhwzp8zIcffsiwYcMIDQ1l1KhRfPXVV15abe9kZmae9FoNBgPz5s1r8/7+9p7++OOPXHTRRaSlpWEwGFi8eHGLryuKwn333UdqaiphYWHMmDGDffv2dfq8zz77LJmZmYSGhjJ58mTWr1/voVfQdR291sbGRv785z8zatQoIiIiSEtL4/rrryc/P7/D5+zJz4I3dPa+zp0796R1n3feeZ0+ry++r9D5623rZ9hgMPDYY4+1+5y++t525bOmvr6eefPmER8fT2RkJJdddhlFRUUdPm9Pf9a7SoIbP7VixQrmzZvH2rVrWbJkCY2NjZx77rnU1NR0+LioqCgKCgqcl8OHD3tpxb0zYsSIFuv+3//+1+59V69ezTXXXMNNN93Eli1bmD17NrNnz2bHjh1eXHHPbNiwocXrXLJkCQBXXHFFu4/xp/e0pqaGMWPG8Oyzz7b59UcffZSnnnqK559/nnXr1hEREcHMmTOpr69v9znff/997r77bu6//342b97MmDFjmDlzJsXFxZ56GV3S0Wutra1l8+bN3HvvvWzevJlPPvmEnJwcLr744k6ftzs/C97S2fsKcN5557VY97vvvtvhc/rq+wqdv17X11lQUMCrr76KwWDgsssu6/B5ffG97cpnze9//3s+//xzPvzwQ1asWEF+fj6XXnpph8/bk5/1blFEQCguLlYAZcWKFe3e57XXXlOio6O9tyg3uf/++5UxY8Z0+f5XXnmlcsEFF7S4bfLkycpvf/tbN6/M8373u98pgwYNUhwOR5tf99f3VFEUBVAWLVrkvO5wOJSUlBTlsccec95WXl6umM1m5d133233eSZNmqTMmzfPed1utytpaWnK/PnzPbLunmj9Wtuyfv16BVAOHz7c7n26+7Ogh7Ze6w033KBccskl3Xoef3hfFaVr7+0ll1yinH322R3exx/eW0U5+bOmvLxcCQ4OVj788EPnfXbv3q0Aypo1a9p8jp7+rHeH7NwEiIqKCgDi4uI6vF91dTUZGRmkp6dzySWXsHPnTm8sr9f27dtHWloaWVlZXHvtteTl5bV73zVr1jBjxowWt82cOZM1a9Z4eplu1dDQwFtvvcWNN97Y4ZBXf31PW8vNzaWwsLDFexcdHc3kyZPbfe8aGhrYtGlTi8cYjUZmzJjhd+93RUUFBoOBmJiYDu/XnZ8FX7J8+XKSkpLIzs7m1ltvpaysrN37BtL7WlRUxJdffslNN93U6X394b1t/VmzadMmGhsbW7xXw4YNY8CAAe2+Vz35We8uCW4CgMPh4K677mLq1KmMHDmy3ftlZ2fz6quv8umnn/LWW2/hcDg4/fTTOXr0qBdX232TJ09m4cKFfPPNNyxYsIDc3Fx+/vOfU1VV1eb9CwsLSU5ObnFbcnIyhYWF3liu2yxevJjy8nLmzp3b7n389T1ti/b+dOe9Ky0txW63+/37XV9fz5///GeuueaaDgcNdvdnwVecd955vPHGG3z//fc88sgjrFixglmzZmG329u8f6C8rwCvv/46Foul02Maf3hv2/qsKSwsJCQk5KSgvKP3qic/693V56aCB6J58+axY8eOTs9np0yZwpQpU5zXTz/9dIYPH84LL7zAww8/7Oll9tisWbOcfx49ejSTJ08mIyODDz74oEu/DfmrV155hVmzZpGWltbuffz1PRXNGhsbufLKK1EUhQULFnR4X3/9Wbj66qudfx41ahSjR49m0KBBLF++nOnTp+u4Ms979dVXufbaaztN9PeH97arnzW+QHZu/Nztt9/OF198wQ8//ED//v279djg4GDGjRvH/v37PbQ6z4iJiWHo0KHtrjslJeWkTP2ioiJSUlK8sTy3OHz4MEuXLuXXv/51tx7nr+8p4Hx/uvPeJSQkEBQU5LfvtxbYHD58mCVLlnS4a9OWzn4WfFVWVhYJCQntrtvf31fNypUrycnJ6fbPMfjee9veZ01KSgoNDQ2Ul5e3uH9H71VPfta7S4IbP6UoCrfffjuLFi1i2bJlDBw4sNvPYbfb2b59O6mpqR5YoedUV1dz4MCBdtc9ZcoUvv/++xa3LVmypMUOh6977bXXSEpK4oILLujW4/z1PQUYOHAgKSkpLd67yspK1q1b1+57FxISwqmnntriMQ6Hg++//97n328tsNm3bx9Lly4lPj6+28/R2c+Crzp69ChlZWXtrtuf31dXr7zyCqeeeipjxozp9mN95b3t7LPm1FNPJTg4uMV7lZOTQ15eXrvvVU9+1nuycOGHbr31ViU6OlpZvny5UlBQ4LzU1tY673Pdddcpf/nLX5zXH3zwQeXbb79VDhw4oGzatEm5+uqrldDQUGXnzp16vIQu+8Mf/qAsX75cyc3NVVatWqXMmDFDSUhIUIqLixVFOfl1rlq1SjGZTMq///1vZffu3cr999+vBAcHK9u3b9frJXSL3W5XBgwYoPz5z38+6Wv+/p5WVVUpW7ZsUbZs2aIAyhNPPKFs2bLFWSH0r3/9S4mJiVE+/fRTZdu2bcoll1yiDBw4UKmrq3M+x9lnn608/fTTzuvvvfeeYjablYULFyq7du1SfvOb3ygxMTFKYWGh11+fq45ea0NDg3LxxRcr/fv3V7Zu3driZ9hqtTqfo/Vr7exnQS8dvdaqqirlj3/8o7JmzRolNzdXWbp0qTJ+/HhlyJAhSn19vfM5/OV9VZTO/x0riqJUVFQo4eHhyoIFC9p8Dn95b7vyWXPLLbcoAwYMUJYtW6Zs3LhRmTJlijJlypQWz5Odna188sknzutd+VnvDQlu/BTQ5uW1115z3ufMM89UbrjhBuf1u+66SxkwYIASEhKiJCcnK+eff76yefNm7y++m6666iolNTVVCQkJUfr166dcddVVyv79+51fb/06FUVRPvjgA2Xo0KFKSEiIMmLECOXLL7/08qp77ttvv1UAJScn56Sv+ft7+sMPP7T571Z7TQ6HQ7n33nuV5ORkxWw2K9OnTz/p7yEjI0O5//77W9z29NNPO/8eJk2apKxdu9ZLr6h9Hb3W3Nzcdn+Gf/jhB+dztH6tnf0s6KWj11pbW6uce+65SmJiohIcHKxkZGQoN99880lBir+8r4rS+b9jRVGUF154QQkLC1PKy8vbfA5/eW+78llTV1en3HbbbUpsbKwSHh6uzJkzRykoKDjpeVwf05Wf9d4wNH1TIYQQQoiAIDk3QgghhAgoEtwIIYQQIqBIcCOEEEKIgCLBjRBCCCECigQ3QgghhAgoEtwIIYQQIqBIcCOEEEKIgCLBjRBCCCECigQ3QgghhAgoEtwIIXxGSUkJt956KwMGDMBsNpOSksLMmTNZtWoVAAaDgcWLF+u7SCGEzzPpvQAhhNBcdtllNDQ08Prrr5OVlUVRURHff/89ZWVlei9NCOFHZOdGCOETysvLWblyJY888ghnnXUWGRkZTJo0iXvuuYeLL76YzMxMAObMmYPBYHBeB/j0008ZP348oaGhZGVl8eCDD2Kz2ZxfNxgMLFiwgFmzZhEWFkZWVhYfffSR8+sNDQ3cfvvtpKamEhoaSkZGBvPnz/fWSxdCuJkEN0IInxAZGUlkZCSLFy/GarWe9PUNGzYA8Nprr1FQUOC8vnLlSq6//np+97vfsWvXLl544QUWLlzIP/7xjxaPv/fee7nsssv46aefuPbaa7n66qvZvXs3AE899RSfffYZH3zwATk5Obz99tstgichhH+RqeBCCJ/x8ccfc/PNN1NXV8f48eM588wzufrqqxk9ejSg7sAsWrSI2bNnOx8zY8YMpk+fzj333OO87a233uL//b//R35+vvNxt9xyCwsWLHDe57TTTmP8+PE899xz3HnnnezcuZOlS5diMBi882KFEB4jOzdCCJ9x2WWXkZ+fz2effcZ5553H8uXLGT9+PAsXLmz3MT/99BMPPfSQc+cnMjKSm2++mYKCAmpra533mzJlSovHTZkyxblzM3fuXLZu3Up2djZ33nkn3333nUdenxDCOyS4EUL4lNDQUM455xzuvfdeVq9ezdy5c7n//vvbvX91dTUPPvggW7dudV62b9/Ovn37CA0N7dL3HD9+PLm5uTz88MPU1dVx5ZVXcvnll7vrJQkhvEyCGyGETzvllFOoqakBIDg4GLvd3uLr48ePJycnh8GDB590MRqb/4tbu3Zti8etXbuW4cOHO69HRUVx1VVX8dJLL/H+++/z8ccfc/z4cQ++MiGEp0gpuBDCJ5SVlXHFFVdw4403Mnr0aCwWCxs3buTRRx/lkksuASAzM5Pvv/+eqVOnYjabiY2N5b777uPCCy9kwIABXH755RiNRn766Sd27NjB//3f/zmf/8MPP2TChAn87Gc/4+2332b9+vW88sorADzxxBOkpqYybtw4jEYjH374ISkpKcTExOjxVyGE6C1FCCF8QH19vfKXv/xFGT9+vBIdHa2Eh4cr2dnZyt///neltrZWURRF+eyzz5TBgwcrJpNJycjIcD72m2++UU4//XQlLCxMiYqKUiZNmqS8+OKLzq8DyrPPPqucc845itlsVjIzM5X333/f+fUXX3xRGTt2rBIREaFERUUp06dPVzZv3uy11y6EcC+plhJCBLy2qqyEEIFLcm6EEEIIEVAkuBFCCCFEQJGEYiFEwJPTdyH6Ftm5EUIIIURAkeBGCCGEEAFFghshhBBCBBQJboQQQggRUCS4EUIIIURAkeBGCCGEEAFFghshhBBCBBQJboQQQggRUP4/hj+gK+jQ0TQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize lists to hold training and evaluation losses and steps\n",
    "train_losses = []\n",
    "eval_losses = []\n",
    "train_steps = []\n",
    "eval_steps = []\n",
    "\n",
    "# Populate the lists from the log history\n",
    "for entry in trainer.state.log_history:\n",
    "    if 'loss' in entry:\n",
    "        train_losses.append(entry['loss'])\n",
    "        train_steps.append(entry['step'])\n",
    "    if 'eval_loss' in entry:\n",
    "        eval_losses.append(entry['eval_loss'])\n",
    "        eval_steps.append(entry['step'])\n",
    "\n",
    "# Plot the losses\n",
    "plt.plot(train_steps, train_losses, label='Train Loss')\n",
    "plt.plot(eval_steps, eval_losses, label='Eval Loss')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-TjT308fowoc"
   },
   "source": [
    "# Evaluate after Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Can set to true for faster inference\n",
    "# model.config.use_cache = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_model is on: cuda:0\n",
      "input_ids are on: cuda:0\n",
      "<｜begin▁of▁sentence｜>\n",
      "### Instruction:\n",
      "What planets are in our solar system?\n",
      "### Response:\n",
      "The planets in our solar system are Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune.\n",
      "\n",
      "Mercury is the smallest planet in our solar system and is the closest to the sun.\n",
      "\n",
      "Venus is the second planet from the sun and is the second largest planet in our solar system.\n",
      "\n",
      "Earth is the third planet from the sun and is the largest planet in our solar system.\n",
      "\n",
      "Mars\n",
      "\n",
      "\n",
      "\n",
      "eval_model is on: cuda:0\n",
      "input_ids are on: cuda:0\n",
      "<｜begin▁of▁sentence｜>\n",
      "### Instruction:\n",
      "What are the first five numbers in the Fibonacci series?\n",
      "### Response:\n",
      "The first five numbers in the Fibonacci series are:\n",
      "\n",
      "1, 1, 2, 3, and 5.\n",
      "\n",
      "These are the first five numbers in the Fibonacci series, which are the numbers in the sequence of numbers that are generated by adding the previous two numbers in the sequence.<｜end▁of▁sentence｜>\n",
      "\n",
      "\n",
      "\n",
      "eval_model is on: cuda:0\n",
      "input_ids are on: cuda:0\n",
      "<｜begin▁of▁sentence｜>\n",
      "### Instruction:\n",
      "Generate a python code snippet to add two numbers.\n",
      "### Response:\n",
      "import math\n",
      "\n",
      "a = 10\n",
      "b = 20\n",
      "\n",
      "c = a + b\n",
      "\n",
      "print(c)<｜end▁of▁sentence｜>\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation(\"base\", tokenizer) #use this if training was done with an adapter preloaded. btw you'll always be running the model at the final checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = save_dir + '/checkpoint-1'\n",
    "# evaluation(\"fine-tuned\", checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iJ0xWylUC1lb",
    "outputId": "58672d9d-7c17-45c5-ddc8-a13cc7512d78"
   },
   "outputs": [],
   "source": [
    "# checkpoint = save_dir + '/checkpoint-15'\n",
    "# evaluation(\"fine-tuned\", checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = save_dir + '/checkpoint-30'\n",
    "# evaluation(\"fine-tuned\", checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = save_dir + '/checkpoint-45'\n",
    "# evaluation(\"fine-tuned\", checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = save_dir + '/checkpoint-60'\n",
    "# evaluation(\"fine-tuned\", checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (476177386.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[45], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    Stop HERE before pushing to Hub. Comment this out to allow the script to proceed.\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Stop HERE before pushing to Hub. Comment this out to allow the script to proceed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6FqNGBAz7ct"
   },
   "source": [
    "# Merge Adapters and Save Model to Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rrwiiYLqG6sp"
   },
   "outputs": [],
   "source": [
    "### Only relevant if trying to load earlier adapters onto the base model.\n",
    "# from peft import PeftModel\n",
    "\n",
    "# adapter_to_push = save_dir + '/checkpoint-60'\n",
    "\n",
    "# # load perf model with new adapters\n",
    "# model_to_push = PeftModel.from_pretrained(\n",
    "#     model,\n",
    "#     adapter_to_push,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VVF0R6ZhBlaf"
   },
   "outputs": [],
   "source": [
    "# Define the save and push paths\n",
    "adapter_model = f\"Trelis/{model_name}-{fine_tune_tag}-adapters\"\n",
    "new_model = f\"Trelis/{model_name}-{fine_tune_tag}\" #adjust 'Trelis' to your HuggingFace organisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e19FlnnCBlrM"
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save_pretrained(f\"{model_name}-{fine_tune_tag}-adapters-local\", push_to_hub=True, use_auth_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.push_to_hub(adapter_model, use_auth_token=True, max_shard_size=\"10GB\", use_safetensors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the trainable_params as well\n",
    "\n",
    "from huggingface_hub import HfApi, create_repo, create_branch\n",
    "\n",
    "create_repo(new_model, private=True)\n",
    "\n",
    "create_branch(new_model, repo_type=\"model\", branch=\"gguf\")\n",
    "\n",
    "# Initialize the HfApi class\n",
    "api = HfApi()\n",
    "\n",
    "# Specify the repository where you want to upload the files\n",
    "repo_id = adapter_model\n",
    "\n",
    "# Array of local file paths you want to upload\n",
    "local_file_paths = [\n",
    "    save_dir + \"/trainable_params_final.bin\",\n",
    "]\n",
    "\n",
    "# Loop through each file and upload it\n",
    "for local_file_path in local_file_paths:\n",
    "    # Extract the file name from the local file path\n",
    "    file_name = local_file_path.split(\"/\")[-1]\n",
    "\n",
    "    # Specify the path where you want the file to be uploaded in the repository\n",
    "    path_in_repo = file_name  # Using file_name directly, adjust as needed\n",
    "\n",
    "    # Upload the file\n",
    "    api.upload_file(\n",
    "        path_or_fileobj=local_file_path,\n",
    "        path_in_repo=path_in_repo,\n",
    "        repo_id=repo_id,\n",
    "        repo_type=\"model\",  # Assuming it's a model; can be \"dataset\" or \"space\" as well\n",
    "    )\n",
    "    print(f\"Uploaded {file_name} to {repo_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zZPgnENAHmuN"
   },
   "outputs": [],
   "source": [
    "### Only needed if doing QLoRA - but you also need some more logic to be able to add in the non-LoRA trained parameters\n",
    "\n",
    "# # from transformers import AutoModelForCausalLM, PretrainedConfig\n",
    "# # import torch\n",
    "\n",
    "# # reload the base model (you might need a pro subscription for this because you may need a high RAM environment since this is loading the full original model, not quantized)\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     base_model,\n",
    "#     quantization_config=bnb_config, # important to merge to the quantized version, otherwise there's small error\n",
    "#     device_map='cpu',\n",
    "#     trust_remote_code=True,\n",
    "#     torch_dtype=torch.float16,\n",
    "#     cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(f\"{model_name}-{fine_tune_tag}-local\")\n",
    "\n",
    "# Save the tokenizer to make sure the updated config is saved as well\n",
    "tokenizer.save_pretrained(f\"{model_name}-{fine_tune_tag}-local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "buqIU-9VJxVV"
   },
   "outputs": [],
   "source": [
    "#Push the tokenizer\n",
    "\n",
    "# # OR Reload from scratch if you don't want pad tokens to be in the tokenizer (which you don't if this makes the tokenizer size not be a multiple of 16)\n",
    "# from transformers import AutoTokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "\n",
    "## SET A CHAT TEMPLATE - RECOMMENDED!\n",
    "# DeepSeek Coder Chat Template\n",
    "tokenizer.chat_template = \"{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{%- set ns = namespace(found=false) -%}{%- for message in messages -%}{%- if message['role'] == 'system' -%}{%- set ns.found = true -%}{%- endif -%}{%- endfor -%}{{bos_token}}{%- if not ns.found -%}{{'You are an AI assistant and you do your best to answer all questions and requests\\n'}}{%- endif %}{%- for message in messages %}{%- if message['role'] == 'system' %}{{ message['content'] }}{%- else %}{%- if message['role'] == 'user' %}{{'Instruction:' + message['content'] + '\\n'}}{%- else %}{{'\\nOutput:' + message['content'] + '\\n<|EOT|>\\n'}}{%- endif %}{%- endif %}{%- endfor %}{% if add_generation_prompt %}{{'\\nOutput:'}}{% endif %}\"\n",
    "\n",
    "tokenizer.push_to_hub(new_model, use_auth_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vTKqNQQpIxL6"
   },
   "outputs": [],
   "source": [
    "model.push_to_hub(new_model, use_auth_token=True, max_shard_size=\"10GB\", use_safetensors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "def download_file_from_huggingface(model_id, filename, save_path):\n",
    "    url = f\"https://huggingface.co/{model_id}/resolve/main/{filename}\"\n",
    "    r = requests.get(url)\n",
    "    if r.status_code != 200:\n",
    "        print(f\"Failed to download {filename}. HTTP Status Code: {r.status_code}\")\n",
    "        return False\n",
    "    with open(os.path.join(save_path, filename), 'wb') as f:\n",
    "        f.write(r.content)\n",
    "    return True\n",
    "\n",
    "def main():\n",
    "    # Files to download and upload\n",
    "    files_to_process = [\"tokenizer.model\", \"README.md\"]\n",
    "    \n",
    "    # Directory to save the downloaded files\n",
    "    save_path = \"./models\"\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    \n",
    "    # Initialize HfApi class\n",
    "    api = HfApi()\n",
    "\n",
    "    # Specify the repository where you want to upload the files\n",
    "    repo_id = new_model  # Assuming new_model is in the format \"username/repo\"\n",
    "\n",
    "    for filename in files_to_process:\n",
    "        # Download the file\n",
    "        success = download_file_from_huggingface(model_id, filename, save_path)\n",
    "        if success:\n",
    "            print(f\"Successfully downloaded {filename}\")\n",
    "        else:\n",
    "            print(f\"Failed to download {filename}\")\n",
    "            continue  # Skip uploading if download failed\n",
    "\n",
    "        # File path to upload\n",
    "        local_file_path = os.path.join(save_path, filename)\n",
    "\n",
    "        # Upload the file\n",
    "        api.upload_file(\n",
    "            path_or_fileobj=local_file_path,\n",
    "            path_in_repo=filename,  # Using filename directly, adjust as needed\n",
    "            repo_id=repo_id,\n",
    "            repo_type=\"model\",  # Assuming it's a model; can be \"dataset\" or \"space\" as well\n",
    "        )\n",
    "        print(f\"Uploaded {filename} to {repo_id}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "trelisEnv",
   "language": "python",
   "name": "trelisenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "043f148d952e482a9029986f99161944": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "051b192ef8e540f3ac0459f74846fad3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_57c5985be925455ab3234b5f78297662",
       "IPY_MODEL_c8ebd46229a446dea6a10f48c2dd7e6d",
       "IPY_MODEL_8dc8ca5c41174894afbc7b944040a889"
      ],
      "layout": "IPY_MODEL_79ea1c4dc6824a06a92de0403f56e64b"
     }
    },
    "06c6dd0b25764569aacdfa2bb01f696f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "090f96cefcd54f17aadec2e8f5a9307b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe2637d90e2045a29826d9023077c314",
      "placeholder": "​",
      "style": "IPY_MODEL_0a01489a78e64a14a54306a3f3c842df",
      "value": "Connecting..."
     }
    },
    "09597bc3af6144eb8ecf874aa4dce884": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0a01489a78e64a14a54306a3f3c842df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0aa8a2f53b2345a8810d5c21226ec164": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3675502942a24bf997ddc5336ed029ee",
      "placeholder": "​",
      "style": "IPY_MODEL_27e63ef320e044f48e8a7efba31c28ef",
      "value": " 414/414 [00:00&lt;00:00, 25.3kB/s]"
     }
    },
    "0aaa13230b4e443dadc3fa9ff0de3d0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0b141f85480a435983a04e95e2404e43": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f211d88f23a4fac9a20aaa2262240f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "10e22f0387474784b426d4d2f6c074cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "13817543df9d468abd3b03b13992228a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "140ca136ec2044b98f3dbc450a9f5c32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b141f85480a435983a04e95e2404e43",
      "placeholder": "​",
      "style": "IPY_MODEL_329d4c2037d94882973c778e43057c27",
      "value": "Downloading (…)/main/tokenizer.json: 100%"
     }
    },
    "14c7809be6de472dad580fb54ad9ca7b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "16cdf8842b33401887430737f31a8a64": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "18180c98496e48f2861cade3dbaf8364": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aaf181f19b93404f9553cb222e531ce9",
      "max": 560,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_86587e97d3c043c99495c35d7505884b",
      "value": 560
     }
    },
    "1c66f0390e8f4621bf20e07b6fc30f85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_140ca136ec2044b98f3dbc450a9f5c32",
       "IPY_MODEL_f83fa03c74ac432792a184dc59268b11",
       "IPY_MODEL_fa46c7632a6b49e3987eaa9534a86bbf"
      ],
      "layout": "IPY_MODEL_260af2c5f38942388d3fb53a75405190"
     }
    },
    "20647bc1b50440be922754fdd7ed36b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d965f10bc3e34578b33c6cbe60913d93",
       "IPY_MODEL_2b0e8656052546adbec382ac6352b058",
       "IPY_MODEL_0aa8a2f53b2345a8810d5c21226ec164"
      ],
      "layout": "IPY_MODEL_ae74ceb23f024206b63118c37a051a79"
     }
    },
    "2267f55d15d04a43959f37d52e786984": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "260af2c5f38942388d3fb53a75405190": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26dab225c11c40d7b36d41f46d091e01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "27e63ef320e044f48e8a7efba31c28ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "27fab833dd854afda14c32ff8c50bb1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2b0e8656052546adbec382ac6352b058": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ff6bbe979c324d4d958207f16cfa5980",
      "max": 414,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_45999b46ef6741e5bb0f80464bbadad4",
      "value": 414
     }
    },
    "2ef6ac7be9464d128f89b69b28e25b40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2fab06b6a0e94d028012babbc5a32d24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_16cdf8842b33401887430737f31a8a64",
      "placeholder": "​",
      "style": "IPY_MODEL_0aaa13230b4e443dadc3fa9ff0de3d0e",
      "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
     }
    },
    "310c95b2dc504cf09322cb7ba891760a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "329d4c2037d94882973c778e43057c27": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3675502942a24bf997ddc5336ed029ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "36797c5c01ba4fbd9944710b6b570c5e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "387a6dba93c54678a3a5404210afd04c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e5923556c18240578703e5d443e6c81c",
       "IPY_MODEL_e909f9afd82d423a967dda899fb2bf1b",
       "IPY_MODEL_465bf049acb64c52933fbfe50f7d4ec7"
      ],
      "layout": "IPY_MODEL_ac6f2cd6604c4c9996ca09e233dd6dbe"
     }
    },
    "3c03abf5267745f99f5b68479ea653d0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3fbaceee3ccf4a64b80d9451d5aa5701": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45999b46ef6741e5bb0f80464bbadad4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "465bf049acb64c52933fbfe50f7d4ec7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_14c7809be6de472dad580fb54ad9ca7b",
      "placeholder": "​",
      "style": "IPY_MODEL_043f148d952e482a9029986f99161944",
      "value": " 129/129 [00:00&lt;00:00, 1.70kB/s]"
     }
    },
    "47641c5f4c8646848374b199b139336f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d900650f66f483b8269b174148659d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "520f2ae3a5ab450db519de663e619530": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "559f7b17cf8d479b89134fbac2ff0de9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d8eabbb772c347a69ddc2cdeb2b4c01f",
      "max": 4400253822,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2ef6ac7be9464d128f89b69b28e25b40",
      "value": 4400253822
     }
    },
    "563634d3c8f14a0a8a3e76f503579221": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "57c5985be925455ab3234b5f78297662": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_13817543df9d468abd3b03b13992228a",
      "placeholder": "​",
      "style": "IPY_MODEL_f5161848f1594f5f8892436974b7f1e6",
      "value": "Downloading (…)okenizer_config.json: 100%"
     }
    },
    "589a72488d9c4553a18761d6966c11a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5bb444edc7ae41208fd39f83fbe98616": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ef6977176435477db177f445401f8fd9",
       "IPY_MODEL_fd2ea82e052642d8bdf66662e2585168",
       "IPY_MODEL_c112af952e5b4bdab733adfc19e2ffec",
       "IPY_MODEL_a5c6c3fbf2174628870f3755ce75e48b"
      ],
      "layout": "IPY_MODEL_902f95f0a23f4fb98156c86e9933ac59"
     }
    },
    "5c37b239dd904c398457b5db01de282b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f579084a40d49f78132406c8e8078e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Login",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_36797c5c01ba4fbd9944710b6b570c5e",
      "style": "IPY_MODEL_10e22f0387474784b426d4d2f6c074cb",
      "tooltip": ""
     }
    },
    "6433bf5eed7d4bd28a954df13b6f0e94": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_589a72488d9c4553a18761d6966c11a2",
      "placeholder": "​",
      "style": "IPY_MODEL_0f211d88f23a4fac9a20aaa2262240f1",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "6834175de25d453f92164ebb336de22b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68892d09649a45d193192824dd8f37f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_848d078ed62443e297125e6532032549",
      "placeholder": "​",
      "style": "IPY_MODEL_6c056bb1731546598a7cdddbab3aaa07",
      "value": " 560/560 [00:00&lt;00:00, 35.0kB/s]"
     }
    },
    "69e55cd3bdbd45aab3e0327d10b7e77c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6c056bb1731546598a7cdddbab3aaa07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6fe96b2d78a340e5874bf90101dedbc3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "79ea1c4dc6824a06a92de0403f56e64b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b3ea7168c824ef8955cbf0c62fbe6ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7ea1b3fcf3174b41b1d38155929526fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06c6dd0b25764569aacdfa2bb01f696f",
      "placeholder": "​",
      "style": "IPY_MODEL_aeb9f39902a341c59b8d346a2558d1d1",
      "value": " 4.40G/4.40G [00:43&lt;00:00, 108MB/s]"
     }
    },
    "809122935aab423d92d71bab8a6f4c4b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "82c56ad017f44a689c53e01527228418": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "847620befc6d4b5d8ab1bd8e613d77cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "848d078ed62443e297125e6532032549": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86587e97d3c043c99495c35d7505884b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8dc8ca5c41174894afbc7b944040a889": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d32f1a6fdec2478d9d7745c39e836c31",
      "placeholder": "​",
      "style": "IPY_MODEL_310c95b2dc504cf09322cb7ba891760a",
      "value": " 776/776 [00:00&lt;00:00, 38.5kB/s]"
     }
    },
    "8fca51abfe404f39a540b39df8df55b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "902f95f0a23f4fb98156c86e9933ac59": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "50%"
     }
    },
    "99c8287b58c74244b0edfe83c49b222a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f8d9a44cbc045a9924949b8685cec3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a3762c02dc5646748f643a912b8df6ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a5c6c3fbf2174628870f3755ce75e48b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ab54aea0b2cf43929af7bb4127974199",
      "placeholder": "​",
      "style": "IPY_MODEL_4d900650f66f483b8269b174148659d5",
      "value": "Login successful"
     }
    },
    "a8599580508045cfa97149579641ce83": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aaf181f19b93404f9553cb222e531ce9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ab54aea0b2cf43929af7bb4127974199": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac6f2cd6604c4c9996ca09e233dd6dbe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae74ceb23f024206b63118c37a051a79": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aeb9f39902a341c59b8d346a2558d1d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "af5a96810c3346c0be5b19e1f532af6f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b146dfc72bac4aa3b5aa75f7f5988083": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b5afaad1a4e74b0a923cb70fa57377dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b675c39bf53947de9387d59eb024c8bb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b90890729a954284ac2e6d1a7289d488": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3fbaceee3ccf4a64b80d9451d5aa5701",
      "placeholder": "​",
      "style": "IPY_MODEL_b5afaad1a4e74b0a923cb70fa57377dc",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "bcfb9c09464546b6aeca67d53badedcf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c112af952e5b4bdab733adfc19e2ffec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b675c39bf53947de9387d59eb024c8bb",
      "placeholder": "​",
      "style": "IPY_MODEL_f8c1ee39e2604e5789a74a16555514ed",
      "value": "Your token has been saved to /root/.cache/huggingface/token"
     }
    },
    "c3b70e90f9234e90bb01dac192725d85": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7f822a2863d45698f4a172fa3d720b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b90890729a954284ac2e6d1a7289d488",
       "IPY_MODEL_559f7b17cf8d479b89134fbac2ff0de9",
       "IPY_MODEL_7ea1b3fcf3174b41b1d38155929526fb"
      ],
      "layout": "IPY_MODEL_bcfb9c09464546b6aeca67d53badedcf"
     }
    },
    "c8dd41732ce7463694555f3486afe470": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6433bf5eed7d4bd28a954df13b6f0e94",
       "IPY_MODEL_18180c98496e48f2861cade3dbaf8364",
       "IPY_MODEL_68892d09649a45d193192824dd8f37f5"
      ],
      "layout": "IPY_MODEL_6834175de25d453f92164ebb336de22b"
     }
    },
    "c8ebd46229a446dea6a10f48c2dd7e6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c37b239dd904c398457b5db01de282b",
      "max": 776,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dbb63cfdc16741efac758d83d227da49",
      "value": 776
     }
    },
    "cd321a86a74842cc804f7647d8182eb1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_82c56ad017f44a689c53e01527228418",
      "max": 499723,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_563634d3c8f14a0a8a3e76f503579221",
      "value": 499723
     }
    },
    "ce690f5848a347f0860e9c3d1704f021": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d32f1a6fdec2478d9d7745c39e836c31": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5548fc995554e51adadfca425377d54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a3762c02dc5646748f643a912b8df6ee",
      "placeholder": "​",
      "style": "IPY_MODEL_7b3ea7168c824ef8955cbf0c62fbe6ae",
      "value": "Downloading tokenizer.model: 100%"
     }
    },
    "d8eabbb772c347a69ddc2cdeb2b4c01f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d94c967a6afc4e708805a7848b171bad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d965f10bc3e34578b33c6cbe60913d93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c3b70e90f9234e90bb01dac192725d85",
      "placeholder": "​",
      "style": "IPY_MODEL_9f8d9a44cbc045a9924949b8685cec3c",
      "value": "Downloading (…)cial_tokens_map.json: 100%"
     }
    },
    "da3974c730cb4ed49097fa8eba66a3d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d5548fc995554e51adadfca425377d54",
       "IPY_MODEL_cd321a86a74842cc804f7647d8182eb1",
       "IPY_MODEL_e2ee97a4ff7f4317af7ee49d4b144aed"
      ],
      "layout": "IPY_MODEL_47641c5f4c8646848374b199b139336f"
     }
    },
    "dbb63cfdc16741efac758d83d227da49": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e2ee97a4ff7f4317af7ee49d4b144aed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_99c8287b58c74244b0edfe83c49b222a",
      "placeholder": "​",
      "style": "IPY_MODEL_2267f55d15d04a43959f37d52e786984",
      "value": " 500k/500k [00:00&lt;00:00, 27.6MB/s]"
     }
    },
    "e5923556c18240578703e5d443e6c81c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8fca51abfe404f39a540b39df8df55b0",
      "placeholder": "​",
      "style": "IPY_MODEL_a8599580508045cfa97149579641ce83",
      "value": "Downloading (…)neration_config.json: 100%"
     }
    },
    "e61ba69b900d4a50b0b7c55eb634b8ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "CheckboxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "CheckboxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "CheckboxView",
      "description": "Add token as git credential?",
      "description_tooltip": null,
      "disabled": false,
      "indent": true,
      "layout": "IPY_MODEL_520f2ae3a5ab450db519de663e619530",
      "style": "IPY_MODEL_69e55cd3bdbd45aab3e0327d10b7e77c",
      "value": true
     }
    },
    "e909f9afd82d423a967dda899fb2bf1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ce690f5848a347f0860e9c3d1704f021",
      "max": 129,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_09597bc3af6144eb8ecf874aa4dce884",
      "value": 129
     }
    },
    "e959704cc7344a43ac3c5b9b9ada5ce4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef6977176435477db177f445401f8fd9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_af5a96810c3346c0be5b19e1f532af6f",
      "placeholder": "​",
      "style": "IPY_MODEL_b146dfc72bac4aa3b5aa75f7f5988083",
      "value": "Token is valid (permission: write)."
     }
    },
    "f096f569b14a49dabc756943593ee15a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f414e130e49e44fca79fe125bebebadf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f5161848f1594f5f8892436974b7f1e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f83fa03c74ac432792a184dc59268b11": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e959704cc7344a43ac3c5b9b9ada5ce4",
      "max": 1842767,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_26dab225c11c40d7b36d41f46d091e01",
      "value": 1842767
     }
    },
    "f8c1ee39e2604e5789a74a16555514ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f95312389a644dd981411afdebd08a55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_809122935aab423d92d71bab8a6f4c4b",
      "placeholder": "​",
      "style": "IPY_MODEL_6fe96b2d78a340e5874bf90101dedbc3",
      "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
     }
    },
    "fa46c7632a6b49e3987eaa9534a86bbf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3c03abf5267745f99f5b68479ea653d0",
      "placeholder": "​",
      "style": "IPY_MODEL_f414e130e49e44fca79fe125bebebadf",
      "value": " 1.84M/1.84M [00:00&lt;00:00, 7.14MB/s]"
     }
    },
    "fd2ea82e052642d8bdf66662e2585168": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f096f569b14a49dabc756943593ee15a",
      "placeholder": "​",
      "style": "IPY_MODEL_847620befc6d4b5d8ab1bd8e613d77cf",
      "value": "Your token has been saved in your configured git credential helpers (store)."
     }
    },
    "fdb27fccde464d4e9420d87bfb465e69": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "PasswordModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "PasswordModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "PasswordView",
      "continuous_update": true,
      "description": "Token:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_d94c967a6afc4e708805a7848b171bad",
      "placeholder": "​",
      "style": "IPY_MODEL_27fab833dd854afda14c32ff8c50bb1a",
      "value": ""
     }
    },
    "fe2637d90e2045a29826d9023077c314": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff6bbe979c324d4d958207f16cfa5980": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
